{"componentChunkName":"component---node-modules-ocular-gatsby-src-templates-search-jsx","path":"/search","webpackCompilationHash":"e8bcf4119e393bc690c8","result":{"pageContext":{"isCreatedByStatefulCreatePages":false,"data":[{"excerpt":"Introduction loaders.gl is a growing suite of portable, framework-independent loaders and writers for a range of file formats. The suite…","rawMarkdownBody":"# Introduction\n\nloaders.gl is a growing suite of portable, framework-independent loaders and writers for a range of file formats. The suite focuses on formats for data visualization, currently including 3D point clouds, 3D geometries and assets (e.g images), geospatial formats as well as tabular data.\n\nloaders.gl is part of the [vis.gl](https://vis.gl) framework ecosystem, and while all loaders and writers in loaders.gl are framework-independent, frameworks like [deck.gl](https://deck.gl) and [luma.gl](https://luma.gl) are designed to easily consume data returned by loaders.gl loaders.\n\n## Major Components\n\n- **Loaders and Writers** - The primary offering is a set of loaders (parsers) for various file formats. loaders.gl also offers of writers (encoders) for subset of those formats to support saving data.\n- **Core Functions** - While loaders can be used directly, A set of functions that take loader objects as parameters and use them to perform actual loading and parsing from strings, ArrayBuffers, urls etc.\n- **Polyfills** - Since loaders.gl is written in modern JavaScript, it depends on some features like `TextDecoder`, `fetch` etc that are not availble in all browsers/Node.js versions. A polyfill module is provided to help when support for older environments.\n\n## Why loaders.gl?\n\nThe open source community has already created many excellent loaders for 3D and geospatial formats available under permissive licenses. However, many of these loaders have limitations (e.g. dependencies on a certain WebGL framework) that can make them hard or even impossible to use in some applications. loaders.gl is an effort to collect some of the best existing open source loaders (together with a handful of newly written loaders) and package them all in a unified, portable, framework-independent way.\n\n## Main Design Goals\n\nSome of the key design goals for loaders.gl.\n\n**Framework Agnostic** - loaders.gl is not tied to any specific framework or use case. Supported file formats are parsed into clearly documented, pure JavaScript data structures.\n\n**Loader Categories** - Loaders in the same category return parsed data in a \"standardized\" way. Thus, all point cloud loaders return typed arrays holding binary data for POSITION, COLOR, etc attributes.\n\n**Binary Data** - Contiguous numeric arrays will always be loaded using JavaScript typed arrays rather than native Arrays.\n\n**Optimized for WebGL** - loaders.gl is optimized for use with WebGL and WebGL frameworks (e.g. by using GPU friendly binary data), however loaders.gl itself does not have any WebGL dependencies.\n\n**Format Autodection** - Applications can work with multiple loaders in a unified way, and loaders.gl can often automatically pick the right loader for a given file.\n\n**Worker Thread Support** - Many loader modules also export a \"worker loader\" that performs parsing on a worker thread.\n\n**Node Support** - All loaders are tested to work under Node.js.\n\n**Bundle Size Conscious** - Each format is published as an independent npm module, and additionally, individual exports from each module are will be removed during tree-shaking if not imported by the app.\n\n## Code Example\n\nApplications import loaders and use them with the `parse` function as follows:\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nconst data = await parse(fetch('data.csv'), CSVLoader);\n```\n\nData will now be a an array of objects representing the parsed rows from the CSV file.\n\n## Licenses\n\nloaders.gl currently contains a collection of MIT and Apache licensed loaders. Each loader comes with its own license, so if the distinction matters to you, please check and decide accordingly. However, loaders.gl will not include any loaders with non-permissive, commercial or copy-left licenses.\n\n## Credits and Attributions\n\nloaders.gl is partly a repackaging of superb work done by many others in the open source community. We try to be as explicit as we can about the origins and attributions of each loader, both in the documentation page for each loader and we also strive to preserve any comments relating to authorship and contributions inside forked source code.\n\nEven so, we can make mistakes, and we may note have the full history of the code we are reusing. If you think that we have missed something, or that we could do better in regard to attribution, please let us know.\n\n## Supported Platforms\n\nOur intention is for loaders.gl to work well on recent versions of the major evergreen browsers (Chrome, Firefox, Safari). We also want to support as Node.js (v10+) when `@loaders.gl/polyfills` is installed.\n\nAssuming `@loaders.gl/polyfills` and additional appropriate polyfills are installed, we also have an ambition that loaders.gl should run on Edge, IE11 and Node.js v8, however testing on these platforms is not extensive.\n","slug":"docs","title":"Introduction"},{"excerpt":"Roadmap We are trying to make the loaders.gl roadmap as public as possible. We share information about the direction of the framework in the…","rawMarkdownBody":"# Roadmap\n\nWe are trying to make the loaders.gl roadmap as public as possible. We share information about the direction of the framework in the following ways:\n\n- **[RFCs](https://github.com/uber-web/loaders.gl/tree/master/dev-docs/RFCs)** - RFCs are technical writeups that describe proposed features in upcoming releases.\n- **[Roadmap Document](https://github.com/uber-web/loaders.gl/tree/master/docs/overview/roadmap)** - (this document) A high-level summary of our current direction for future releases.\n- **[Blog](https://medium.com/@vis.gl)** - We use the vis.gl blog to share information about what we are doing.\n- **[Github Issues](https://github.com/uber-web/loaders.gl/issues)** - The traditional way to start or join a discussion.\n\n## Feature Roadmap\n\n**Off-thread parsing support** - Off thread parsing is an obvious optimization however it has some major complications that often eat up any performance gains: and serialization/deserialization overhead. loaders.gl is designed to avoid serialization through direct transfer of typed arrays.\n\n**Loader Worker Thread Pool** - Another performance \"killer\" for worker threads is multi-second startup time. loaders.gl exports an optional \"loader worker manager\" class that can help keep a loader thread pool loaded and primed and ready to start off-thread parsing as soon as data arrives on the wire.\n\n**Progress Tracking** - loaders can provide progress callbacks and a `ProgressTracker` class is provided to track the progress of a set of parallel loads.\n\n**Improved Format Auto-Discovery** - Each loader can optionally expose a test function that can examine the \"head\" of a file to test if it is likely to be in a format this loader will be able to parse.\n\n**Automatic Timing** - objects returned from loaders could contain a `stats` object with timing stats.\n\n**Default Settings** - Set `setDefaultOptions({stats: true})` to enable stats collection, etc.\n\n**MIME types** - Allow MIME types (e.g. from response headers) to be provided to assist in loader auto-selection. Enable Writers to return recommended MIMEtypes.\n\n\n## Format Roadmap\n\n### Scenegraph Formats\n\n- We expect loaders.gl to have very solid (\"reference caliber\") glTF/GLB implementation.\n- Support for glTF extensions that can be handled during the load phase (many can only be handled during rendering).\n- Given the emergence of glTF as a major Khronos standard, and availability of good glTF conversion tools and exporters, we will most likely not implement any other scene/mesh description formats such as COLLADA.\n\n### Point Clouds\n\nStill, for special data sets such as large point clouds or complex geospatial data, the need for special formats for (e.g. compactness or expressivity) is unchanged, so this is the direction we expect most new loaders.gl loaders to focus on.\n\n### Meshes\n\n- Currently no support beyond OBJ.\n- For OBJ, should we support MTL?\n\n### Massive Point Clouds/Data Sets\n\n* 3D Tiles\n* potree?\n\nThese critically need to include traversal and tile loading caches\n\n### Other loaders\n\nFinally, some \"unusual\" loaders may be included just for fun, e.g. SVG tesselation.\n","slug":"docs/roadmap","title":"Roadmap"},{"excerpt":"Upgrade Guide v1.1 (In Development) A couple of functions have been deprecated and will be removed in v2.0. They now emit console warnings…","rawMarkdownBody":"# Upgrade Guide\n\n## v1.1 (In Development)\n\nA couple of functions have been deprecated and will be removed in v2.0. They now emit console warnings. Start replacing your use of these functions now to remove the console warnings and ensure a smooth future upgrade to v2.0.\n\nAlso, Node support now requires installing `@loaders.gl/polyfills` before use.\n\n### @loaders.gl/core\n\n- Removal: Node support for `fetchFile` now requires importing `@loaders.gl/polyfills` before use.\n- Removal: Node support for `TextEncoder`, and `TextDecoder` now requires importing `@loaders.gl/polyfills` before use.\n- Deprecation: `TextEncoder` and `TextDecoder` will not be exported from `loaders.gl/core` in v2.0.\n\n### @loaders.gl/images\n\n- Removal: Node support for images now requires importing `@loaders.gl/polyfills` before use.\n\n### @loaders.gl/gltf\n\n- Deprecation: `GLBParser`/`GLBBuilder` - These will be merged into GLTF classes..\n- Deprecation: `GLTFParser`/`GLTFBuilder` - The new `GLTF` class can hold GLTF data and lets application access/modify it.\n- Deprecation: `GLTFLoader` will no longer return a `GLTFParser` object in v2.0. Instead it will return a pure javascript object containing the parse json and any binary chunks. This object can be accessed through the `GLTF` class. Set `options.GLTFParser` to `false` to opt in to the new behavior now.\n\n## v1.0\n\nFirst official release of loaders.gl.\n","slug":"docs/upgrade-guide","title":"Upgrade Guide"},{"excerpt":"Contributing Contributions are welcome, assuming that they align with the general design goals and philosophy of the repo. Unless you just…","rawMarkdownBody":"# Contributing\n\nContributions are welcome, assuming that they align with the general design goals and philosophy of the repo.\n\nUnless you just want to contribute a small bug fix, it is a good idea to start by opening an issue and discuss your idea with the maintainers. This maximizes the chances that your contribution will be accepted once you open a pull request.\n\n## Configuring Your Development Environment\n\nTo contribute, you will likely want to clone the loaders.gl repository and make sure you can install, build and run tests.\n\nOur primary development environment is MacOS, but it is possible to build loaders.gl on Linux and Windows (using a Linux environment).\n\n### Setting up Linux Environment on Windows 10\n\nIt is possible to build under Windows, but not directly in the Windows command prompt. You will need to install a Linux command line environment.\n\nInstall [WSL (Windows Subsystem for Linux)](https://docs.microsoft.com/en-us/windows/wsl/install-win10) on Windows 10.\n\n### Install Node and NPM\n\n```bash\nsudo apt update\nsudo apt install nodejs\n```\n\n### Option: Install NVM\n\n- `https://www.liquidweb.com/kb/how-to-install-nvm-node-version-manager-for-node-js-on-ubuntu-12-04-lts/`\n- `https://github.com/nvm-sh/nvm/releases`\n\n### Install yarn\n\nhttps://www.hostinger.com/tutorials/how-to-install-yarn-on-ubuntu/\n\n```bash\nsudo apt update\nsudo apt install yarn nodejs\nyarn –version\n```\n\n### Install jq\n\n```bash\nsudo apt-get install jq\n```\n\n### Configuring your System\n\nOn Linux Systems Install packages\n\n- mesa-utils\n- xvfb\n- libgl1-mesa-dri\n- libglapi-mesa\n- libosmesa6\n- libxi-dev\n\nTo get the headless tests working: export DISPLAY=:99.0; sh -e /etc/init.d/xvfb start\n\n## Running Tests\n\n- `yarn lint`: Check coding standards and formatting\n- `yarn lint fix`: Fix errors with formatting\n- `yarn test node`: Quick test run under Node.js\n- `yarn test browser`: Test run under browser, good for interactive debugging\n- `yarn test`: Run lint, node test, browser tests (in headless mode)\n","slug":"docs/contributing","title":"Contributing"},{"excerpt":"What's New v1.2 (In Development, alpha/beta releases available) Release Date: Aug 8, 2019 : File Type Auto Detection now supports binary…","rawMarkdownBody":"# What's New\n\n## v1.2 (In Development, alpha/beta releases available)\n\nRelease Date: Aug 8, 2019\n\n- `@loaders.gl/core`: File Type Auto Detection now supports binary files\n- `@loaders.gl/polyfills`: Fixed `TextEncoder` warnings\n- `@loaders.gl/arrow`: Improved Node 8 support\n- `@loaders.gl/images`: Image file extensions now added to loader object\n- `@loaders.gl/gltf`: Generate default sampler parameters if none provided in gltf file\n\n### @loaders.gl/3d-tiles <sup>EXPERIMENTAL</sup>\n\n- Support for dynamic traversal of 3D tilesets (automatically loads and unloads tiles based on viewer position and view frustum).\n- Support for loading tilesets from Cesium ION servers.\n- Asynchronous tileset loading\n- Auto centering of view based on tileset bounding volumes\n- deck.gl `Tile3DLayer` class provided in examples.\n\n## v1.1\n\nRelease Date: May 30, 2019\n\n### @loaders.gl/core\n\n- `fetchFile` function - Can now read browser `File` objects (from drag and drop or file selection dialogs).\n- `isImage(arrayBuffer [, mimeType])` function <sup>ENHANCED</sup> - can now accept a MIME type as second argument.\n\n### @loaders.gl/images\n\n- `getImageMIMEType(arrayBuffer)` function <sup>NEW</sup> - returns the MIME type of the image in the supplied `ArrayBuffer`.\n- `isImage(arrayBuffer [, mimeType])` function <sup>ENHANCED</sup> - can now accept a MIME type as second argument.\n\n### @loaders.gl/gltf\n\nThe glTF module has been refactored with the aim of simplifying the loaded data and orthogonalizing the API, as well as allowing 'embedded' GLB data inside other binary formats to be parsed (e.g. the glTF parser can now extract embedded glTF inside 3D tile files).\n\n- [`GLTFScenegraph`](/docs/api-reference/gltf/gltf-scenegraph) class <sup>NEW</sup> - A helper class that provides methods for structured access to and modification/creation of glTF data.\n- [`postProcessGLTF`](/docs/api-reference/gltf/post-process-gltf) function <sup>NEW</sup> - Function that performs a set of transformations on loaded glTF data that simplify application processing.\n- [`GLBLoader`](/docs/api-reference/gltf/glb-loader)/[`GLBWriter`] <sup>NEW</sup> - loader/writer pair that enables loading/saving custom (non-glTF) data in the binary GLB format.\n- [`GLTFLoader`](/docs/api-reference/gltf/gltf-loader) <sup>ENHANCED</sup> - can now return the pure JavaScript object defined by the [GLTF category](/docs/api-reference/gltf/category-gltf), letting application separately handle post-processing etc.\n\n### @loaders.gl/3d-tiles <sup>NEW MODULE</sup>\n\n- Support for the 3D tiles format is being developed in the new `@loaders.gl/3d-tiles` module.\n- Loading of individual point cloud tiles, including support for Draco compression and compact color formats such as RGB565 is supported.\n\n### @loaders.gl/polyfills <sup>NEW MODULE</sup>\n\nNode support now requires importing `@loaders.gl/polyfills` before use. This reduces the number of dependencies, bundle size and potential build complications when using other loaders.gl modules when not using Node.js support.\n\n### @loaders.gl/loader-utils <sup>NEW MODULE</sup>\n\nHelper functions for loaders have been broken out from `@loaders.gl/core`. Individual loaders no longer depend on`@loaders.gl/core` but only on `@loaders.gl/loader-utils`.\n\n## v1.0\n\nRelease Date: April 2019\n\n- First Official Release\n","slug":"docs/whats-new","title":"What's New"},{"excerpt":"Using Loaders loaders.gl has parser functions that use so called \"loaders\" to convert the raw data loaded from files into parsed objects…","rawMarkdownBody":"# Using Loaders\n\nloaders.gl has parser functions that use so called \"loaders\" to convert the raw data loaded from files into parsed objects. Each loader encapsulates a parsing function for one file format (or a group of related file formats) together with some metadata (like the loader name, common file extensions for the format etc).\n\n## Installing loaders\n\nloaders.gl provides a suite of pre-built loader objects packaged as scoped npm modules. The intention is that applications will install and import loaders only for the formats they need.\n\n## Using Loaders\n\nLoaders can be passed into utility functions in the loaders.gl core API to enable parsing of the chosen format.\n\n## Creating New Loaders\n\n> See the a detailed specification of the [loader object format API reference](docs/api-reference/specifications/loader-object-formats).\n\nApplications can also create new loader objects. E.g. if you have existing JavaScript parsing functionality that you would like to use with the loaders.gl core utility functions.\n\nYou would give a name to the loader object, define what file extension(s) it uses, and define a parser function.\n\n```js\nexport default {\n  name: 'JSON',\n  extensions: ['json'],\n  testText: null,\n  parseTextSync: JSON.parse\n};\n```\n\n| Field       | Type     | Default  | Description                                                     |\n| ----------- | -------- | -------- | --------------------------------------------------------------- |\n| `name`      | `String` | Required | Short name of the loader ('OBJ', 'PLY' etc)                     |\n| `extension` | `String` | Required | Three letter (typically) extension used by files of this format |\n| `testText` | `Function` | `null`  | Guesses if a file is of this format by examining the first characters in the file |\n\nA loader must define a parser function for the format, a function that takes the loaded data and converts it into a parsed object.\n\nDepending on how the underlying loader works (whether it is synchronous or asynchronous and whether it expects text or binary data), the loader object can expose the parser in a couple of different ways, specified by provided one of the parser function fields.\n","slug":"docs/developer-guide/about-loaders","title":"Using Loaders"},{"excerpt":"Using Writers Writers and the  functions are still in development, and while they can be used may still have issues. For a detailed…","rawMarkdownBody":"# Using Writers\n\n> Writers and the `encode` functions are still in development, and while they can be used may still have issues.\n\n> For a detailed specification of the writer object format see the [API reference](docs/api-reference/specifications/writer-object-formats.md).\n\nTBA\n","slug":"docs/developer-guide/about-writers","title":"Using Writers"},{"excerpt":"Get Started Installing Install loaders.gl core and loader for any modules you would like to use. Each format is published as a separate npm…","rawMarkdownBody":"# Get Started\n\n## Installing\n\nInstall loaders.gl core and loader for any modules you would like to use.\n\nEach format is published as a separate npm module.\n\n```bash\nyarn add @loaders.gl/core\nyarn add @loaders.gl/gltf\n...\n```\n\n## Using\n\nYou can import a loader and use it directly with `parse`. Note that `parse` can accept a `fetch` response object as the source of data to be parsed:\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nconst data = await parse(fetch('data.csv'), CSVLoader);\n```\n\nYou can register loaders after importing them\n\n```js\nimport {registerLoaders} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nregisterLoaders(CSVLoader);\n```\n\nThen, in the same file (or some other file in the same app) that needs to load CSV, you no longer need to supply the loader to `parse`. It will autodetect the pre-registered loader:\n\n```js\nimport {parse} from '@loaders.gl/core';\n\n// The pre-registered CSVLoader gets auto selected based on file extension...\nconst data = await parse(fetch('data.csv'));\n```\n\n## Building\n\nloaders.gl is designed to leverage modern JavaScript (ES2018) and to optimize functionality and performance on evergreen browsers.\n\nHowever, the default distribution is completely transpiled to ES5 so using loaders.gl with older or \"slower moving\" browsers such as IE11 and Edge is possible if polyfills are added.\n\n## Supporting Older Browsers\n\nTo build on Edge and IE11, `TextEncoder` and `TextDecoder` must be polyfilled. There are several polyfills available on `npm`, but you can also use the polyfills provided by loaders.gl:\n\n```bash\nyarn install @loaders.gl/polyfills\n```\n\n```js\nimport '@loaders.gl/polyfills';\n```\n\n## Supporting Node.js\n\nA number of polyfills for `fetch`, `TextEncoder` etc are available to make loaders.gl work under Node.js, just install the `@loaders.gl/polyfills module` as described above.\n","slug":"docs/developer-guide/get-started","title":"Get Started"},{"excerpt":"Polyfills Older browsers (mainly Edge and IE11) as well as Node.js do not provide certain APIs (,  etc) that loaders.gl depends on. The good…","rawMarkdownBody":"## Polyfills\n\nOlder browsers (mainly Edge and IE11) as well as Node.js do not provide certain APIs (`TextEncoder`, `fetch` etc) that loaders.gl depends on.\n\nThe good news is that these APIs can be provided by the application using the [polyfill](https://en.wikipedia.org/wiki/Polyfill_(programming)) technique.\n\nWhile there are many good polyfill modules for these classes available on `npm`, to make the search for a version that is guaranteed to work with loaders.gl a little easier, the `@loaders.gl/polyfills` module is provided.\n\nTo install these polyfills, just `import` the polyfills module before start using loaders.gl.\n\n```js\nimport '@loaders.gl/polyfills';\nimport {parse} from '@loaders.gl/core';\n```\n\n## Combining with other Polyfills\n\nloaders.gl only installs polyfills if the corresponding global symbol is `undefined`. This means that if another polyfill is already installed when `@loaders.gl/polyfills` is imported, the other polyfill will remain in effect. Since most polyfill libraries work this way, applications can mix and match polyfills by ordering the polyfill import statements appropriately (but see the remarks below for a possible caveat).\n\n\n## Provided Polyfills\n\nSee [API Reference](/docs/api-reference/polyfills).\n\n## Remarks\n\nApplications should typically only install this module if they need to run under older environments. While the polyfills are only installed at runtime if the platform does not already support them, they will still be included in your application bundle, i.e. importing the polyfill module will increase your application's bundle size.\n\nWhen importing polyfills for the same symbol from different libraries, the import can depend on how the other polyfill is written. to control the order of installation, you may want to use `require` rather than `import` when importing `@loaders.gl/polyfills`. As a general rule, `import` statements execute before `require` statments.\n\n","slug":"docs/developer-guide/polyfills","title":" Polyfills"},{"excerpt":"Loader Categories loaders.gl defines \"categories\" of loaders that load very similar data (e.g. point clouds). When it is reasonably easy to…","rawMarkdownBody":"# Loader Categories\n\nloaders.gl defines \"categories\" of loaders that load very similar data (e.g. point clouds). When it is reasonably easy to do so, loaders.gl converts the returned data in a standardized format for that category. This allows an application to support multiple formats with a single code path, since all the loaders will return similar data structures.\n\nCurrently defined categories:\n\n- Meshes/Point Cloud (overlaps with Point Clouds and shares format)\n- GeoJSON\n\n## Common Format of Loaded Data\n\nOn a successful parse, all loaders will return a data object with a minimal standardized payload as follows:\n\n| Field        | Type                | Contents                                                                                                                                                                       |\n| ------------ | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| `loaderData` | `Object` (Optional) | Loader and format specific data, such as e.g. original header fields. Can correspond one-to-one with the data in the specific file format itself, or be defined by the loader. |\n| `header`     | `Object`            | Standardized header information - can contain number of vertices, etc.                                                                                                         |\n| `...`        | `*`                 | Standardized data, depends on which \"category\" the loader conforms to                                                                                                          |\n\n> `loaderData` should not be considered stable between releases, since loaders.gl can choose to replace the underlying loader for performance or feature reasons.\n\n### Binary Data\n\nloaders.gl will attempt to load any data that is a contiguous array of numbers as a typed array (causing that data to be stored as a contiguous array of binary memory).\n","slug":"docs/developer-guide/loader-categories","title":"Loader Categories"},{"excerpt":"KMLLoader KML (Keyhole Markup Language) is an XML-based file format used to display geographic data in an Earth browser such as Google Earth…","rawMarkdownBody":"# KMLLoader\n\nKML (Keyhole Markup Language) is an XML-based file format used to display geographic data in an Earth browser such as Google Earth (originally named \"Keyhole Earth Viewer\"). It can be used with any 2D or 3D maps.\n\nReferences:\n\n- [Keyhole Markup Language - Wikipedia](https://en.wikipedia.org/wiki/Keyhole_Markup_Language)\n- [KML Tutorial - Google](https://developers.google.com/kml/documentation/kml_tut)\n\n## Usage\n\n```js\nimport {KMLLoader} from '@loaders.gl/kml';\nimport {load} from '@loaders.gl/core';\n```\n\n## Structure of Loaded Data\n\nThe parser will return a JavaScript object with a number of top-level array-valued fields:\n\n| Field           | Description                        |\n| --------------- | ---------------------------------- |\n| `documents`     |                                    |\n| `folders`       |                                    |\n| `links`         |                                    |\n| `points`        | Points                             |\n| `lines`         | Lines                              |\n| `polygons`      | Polygons                           |\n| `imageoverlays` | Urls and bounds of bitmap overlays |\n\n## Parser Options\n\n> Work in progress\n\n| Option            | Default | Description                                                                                                |\n| ----------------- | ------- | ---------------------------------------------------------------------------------------------------------- |\n| `useLngLatFormat` | `true`  | KML longitudes and latitudes are specified as `[lat, lng]`. This option \"normalizes\" them to `[lng, lat]`. |\n| `useColorArrays`  | `true`  | Convert color strings to arrays                                                                            |\n\n## Limitations\n\n- Currently XML parsing is only implemented in browsers, not in Node.js. Check `KMLLoader.supported` to check at run-time.\n\n## License/Credits/Attributions\n\nLicense: MIT\n\n`XMLLoader` is an adaptation of Nick Blackwell's [`js-simplekml`](https://github.com/nickolanack/js-simplekml) module.\n","slug":"docs/api-reference/geojson-loaders/kml-loader","title":"KMLLoader"},{"excerpt":"GeoJSON Loader Category Many geospatial formats can be converted to GeoJSON (sometimes with a loss of some information). Since most…","rawMarkdownBody":"# GeoJSON Loader Category\n\nMany geospatial formats can be converted to GeoJSON (sometimes with a loss of some information). Since most geospatial pplications can consume geojson, it can make sense to provide a GeoJSON conversion option for geospatial loaders.\n","slug":"docs/api-reference/geojson-loaders/category-geojson","title":"GeoJSON Loader Category"},{"excerpt":"GLTF Category Features (Deprecated) GLTFBuilder API A glTF file can be built programmatically using the GLTFBuilder's \"fluent API\": Adding…","rawMarkdownBody":"# GLTF Category Features (Deprecated)\n\n## GLTFBuilder API\n\nA glTF file can be built programmatically using the GLTFBuilder's \"fluent API\":\n\n```js\nconst builder = new GLTFBuilder(...)\n  .addApplicationData(...);\n  .addExtras(...);\n  .addExtension(...);\n  .addRequiredExtension(...)\n  .encodeAsGLB(...);\n```\n\n## Adding Custom Payloads to glTF files\n\nglTF provides multiple mechanisms for adding custom data to a glTF conformant file. The application just needs to decide where to store it. Normally it should be added using one of the `addApplicationData`, `addExtras`, `addExtension` or `addRequiredExtension` methods.\n\n### Binary Packing of Typed Arrays in JSON Data\n\nThe `GLTFLoader` and `GLTFBuilder` classes include support for moving (packing) typed arrays in the application JSON into the binary GLB chunk.\n\nThe packing process extracts binary (typed) arrays from the supplied `json` data structure, placing these in compact binary chunks (by calling the appropriate `add...` methods on the builder). The \"stripped\" JSON chunk will contain \"JSON pointers\" that the `GLTFParser` can later use to restore the JSON structure on load.\n\n### Flattening Nested Numeric Arrays\n\nAs an option, standard JavaScript arrays can also be stored in the binary chunk under certain conditions. This feature supports arrays that contain only numbers. It also supports arrays that also contain nested arrays that only contain numbers.\n\nThe major complication when packing nested arrays is that the internal structure is lost. For instance, a coordinate array `[[1, 2, 0], [2, 1, 0]]` will be packed and unpacked as `[1, 2, 0, 2, 1, 0]`. To assist with recovering this information, the flattening process estimates the `size` of top-level elements and stored as a named field on the typed array.\n","slug":"docs/api-reference/deprecated/category-gltf-deprecated","title":"GLTF Category Features (Deprecated)"},{"excerpt":"GLBBuilder (Deprecated) This class will be removed in v2.0. Use the  or the  class instead. The  class allows applications to use a \"fluent…","rawMarkdownBody":"# GLBBuilder (Deprecated)\n\n> This class will be removed in v2.0. Use the `GLBWriter` or the `GLTFScenegraph` class instead.\n\nThe `GLBBuilder` class allows applications to use a \"fluent\" API to dynamically build up a hybrid JSON/binary GLB file. The `GLBBuilder` would normally be used if you want to save custom mixed JSON/binary data in a \"GLB envelope\".\n\nReferences:\n\n- For more information, see [glTF and GLB support](docs/) in the Developer's Guide.\n\n## Usage\n\nAdding binary data sub chunks to the GLB file, then calling encode to generate the complete `arrayBuffer`.\n\n```js\nimport {GLBBuilder} from '@loaders.gl/gltf';\nimport {saveBinaryFile} from '@loaders.gl/core';\n\nconst gltfBuilder = new GLBBuilder();\n\nconst IMAGE_DATA = ...; // Image as ArrayBuffer\nconst imageIndex = gltfBuilder.addImage(IMAGE_DATA);\n\n// Add custom JSON in top-level glTF object\ngltfBuilder.addApplicationData('app-key', {...});\n\n// All data added, we can encode\nconst arrayBuffer = gltfBuilder.encodeAsGLB();\n\n// The encoded `ArrayBuffer` represents a complete binary representation of the data that can be written atomically to file\nsaveBinaryFile(filename, arrayBuffer);\n```\n\n## Methods\n\n### constructor()\n\nCreates a new `GLBBuilder` instance.\n\n### encodeSync(options : Object) : ArrayBuffer\n### encodeAsGLB(options : Object) : ArrayBuffer\n\nCombines your added JSON data structures () with any generated JavaScript and any binary subchunks, into a single GLB encoded `ArrayBuffer` that can be written directly to file.\n\n- `options.packTypedArrays` - Packs typed arrays\n\nNote: `encode()` is a one time operation. It should only be called once all data and binary buffers have been added to the builder.\n\n### encodeAsGLBWithJSON(options : Object) : Object\n\nA version of `encode` that returns the final arrayBuffer together with the generated JSON. Note that the returned `arrayBuffer` contains the JSON and is identical to the `encodeAsGLB`.\n\n### addApplicationData(key : String, data : any [, packOptions: Object])\n\nStores the supplied `data` in the given top-level field given by `key`.\n\nThe data object will be encoded as JSON before being stored. By default, any typed arrays in the data object will be removed fromn the data payload and packed in the binary chunk.\n\n- `packOptions.packTypedArrays` - Packs typed arrays into the binary chunk\n- `packOptions.flattenArrays` - Flatten \"nested\" standard JavaScript arrays into typed arrays (and then pack them into the binary chunk).\n\n### addBuffer(typedArray : TypedArray, accessor = {size: 3} : Object) : Number\n\nAdds one binary array intended to be loaded back as a WebGL buffer.\n\n- `typedArray` -\n- `accessor` - {size, type, ...}.\n\nType is autodeduced from the type of the typed array.\n\nThe binary data will be added to the GLB BIN chunk, and glTF `bufferView` and `accessor` fields will be populated.\n\n### addImage(typedArray: TypedArray) : Number\n\nAdds a glTF image. The binary image data will be added to the GLB BIN chunk, and glTF `bufferView` and `image` fields will be populated.\n","slug":"docs/api-reference/deprecated/glb-builder","title":"GLBBuilder (Deprecated)"},{"excerpt":"GLTFParser (Deprecated) This class will be removed in v2.0. Use the  class instead. The  class parses GLB-encoded glTF files. glTF files can…","rawMarkdownBody":"# GLTFParser (Deprecated)\n\n> This class will be removed in v2.0. Use the [`GLTFScenegraph`] class instead.\n\nThe `GLTFParser` class parses GLB-encoded glTF files. glTF files can contain complex scenegraphs with extensions and application defined data annotations.\n\nTo facilitiate working with the loaded data, the `GLTFParser` class provides:\n\n- A set of accessor methods to facilitate traversal the parsed glTF data.\n- A `resolveScenegraphs` method that resolves the index based linking between objects into a hierarchical javascript structure.\n\nCertain glTF extensions can be fully or partially processed by the `GLTFParser`. See [glTF Extensions](docs/api-reference/gltf-loaders/gltf-extensions.md).\n\nReferences:\n\n- For more information, see [glTF and GLB support](docs/) in the Developer's Guide.\n\n## Usage\n\n```js\nimport {GLTFParser} from '@loaders.gl/gltf';\nimport {load} from '@loaders.gl/core';\n\n// Create a parser\nconst gltfParser = new GLTFParser();\n\n// Load and parse a file\nconst GLTF_BINARY = await load(...);\ngltfParser.parseSync(GLTF_BINARY);\n\n// Get the complete glTF JSON structure\nconst gltfJson = gltfParser.getJSON();\n\n// Get specific top-level fields from the glTF JSON chunk\nconst appData = gltfParser.getApplicationData('customData');\n\n// Get a top level extension from the glTF JSON chunk\nconst topLevelExtension = gltfParser.getExtension('ORGNAME_extensionName');\nif (topLevelExtension) {\n  ...\n}\n\n// Get images from the binary chunk (together with metadata)\nconst imageIndex = 0;\nconst image = gltfParser.getImage(imageIndex);\n\n// Get default glTF scenegraph\nconst scenegraph = gltfParser.getScenegraph();\n// Get specific glTF scenegraph\nconst scenegraph = gltfParser.getScenegraph(2);\n```\n\n## Structure of Loaded Data\n\nThe structure of the parsed data is as described in the glTF specification, with binary buffers and images resolved into typed arrays.\n\nCalling the `resolveScenegraphs` method adds a hierarchical structure that makes the scenegraph easier to traverse. After the call, each parent object in the scenegraph will contain an array of child objects, instead of a list of child indices.\n\n## Methods\n\n### constructor()\n\nCreates a new `GLTFParser` instance.\n\n### async parse(arrayBuffer : ArrayBuffer, options : Object) : Promise.Object\n\nParses an in-memory, glTF/GLB formatted `ArrayBuffer` a JSON tree with binary typed arrays and image nodes. Once the `Promise` returned by the `parse()` method has successfully resolved, the accessors in this class can be used.\n\n- `options.url`= - Supplies a base URL that is used to resolve relative file names to linked resources. Only needed when loading glTF files that have linked resources (e.g. typically not the case for `.glb` encoded files).\n- `options.decompress`=`false` - Decompresses any Draco encoded meshes\n- `options.DracoDecoder` - To enable Draco encoding, the application also needs to import and supply the `DracoEncoder` class.\n\nNotes:\n\n- linked binary resources will be loaded and resolved (if url is available).\n- base64 encoded binary data inside the JSON payload will be decoded\n\n### parseSync(arrayBuffer : ArrayBuffer, options : Object) : Object\n\nParses an in-memory, glTF/GLB formatted `ArrayBuffer` a JSON tree with binary typed arrays and image nodes.\n\nOnce the `parseSync()` method has successfully completed the accessors in this class can be used.\n\nNotes:\n\n- **Synchronous parsing does not handle linked resources**\n\n### resolveScenegraphs() : Object\n\nThe `resolveScenegraphs` method resolves the index based linking between objects into a hierarchical javascript structure, making scenegraph traversal simpler.\n\n### getApplicationData(key : String) : Object\n\nReturns the given data field in the top-level glTF JSON object.\n\n### getExtraData(key : String) : Object?\n\nReturns a key in the top-level glTF `extras` JSON object.\n\n### getExtension(name : String) : Object?\n\nReturns the top-level extension by `name`, if present.\n\n### getUsedExtensionNames() : String[]\n\nReturns an array of extension names (covering all extensions used at any level of the glTF hierarchy).\n\n### getRequiredExtensionNames() : String[]\n\nReturns an array of extensions at any level of the glTF hierarchy that are required to properly display this file (covering all extensions used at any level of the glTF hierarchy).\n\n### getScenegraph([index : Number]) : Object?\n\nReturns the Scenegraph with the given index, or the default scenegraph if no index is specified.\n\n### getImage(index : Number) : Object\n\nReturns the image with specified index\n","slug":"docs/api-reference/deprecated/gltf-parser","title":"GLTFParser (Deprecated)"},{"excerpt":"GLTFBuilder (Deprecated)  will be removed in v2.0. Use the  class instead. The  class allows applications to use a \"fluent\" API to…","rawMarkdownBody":"# GLTFBuilder (Deprecated)\n\n> `GLTFBuilder` will be removed in v2.0. Use the [`GLTFScenegraph`] class instead.\n\nThe `GLTFBuilder` class allows applications to use a \"fluent\" API to dynamically build up a hybrid JSON/binary GLB file. The `GLTFBuilder` would normally be used if you want to save custom mixed JSON/binary data in a \"GLB envelope\".\n\nReferences:\n\n- For more information, see [glTF and GLB support](docs/) in the Developer's Guide.\n\n## Usage\n\nAdding binary data sub chunks to the GLB file, then calling encode to generate the complete `arrayBuffer`.\n\n```js\nimport {GLTFBuilder} from '@loaders.gl/gltf';\nimport {saveBinaryFile} from '@loaders.gl/core';\n\n\nconst gltfBuilder = new GLTFBuilder();\n\nconst IMAGE_DATA = ...; // Image as ArrayBuffer\nconst imageIndex = gltfBuilder.addImage(IMAGE_DATA);\n\n// Add custom JSON in top-level glTF object\ngltfBuilder.addApplicationData('app-key', {...});\n\n// Add custom JSON in glTF extras field\ngltfBuilder.addExtraData('app-key', {...});\n\n// Add custom JSON in an optional glTF extension object.\ngltfBuilder.addExtension('ORGNAME_extension_1', {...});\n\n// Add custom JSON into a required glTF extension object.\ngltfBuilder.addRequiredExtension('ORGNAME_extension_2', {...});\n\n// All data added, we can encode\nconst arrayBuffer = gltfBuilder.encodeAsGLB();\n\n// The encoded `ArrayBuffer` represents a complete image of the data\nsaveBinaryFile(filename, arrayBuffer);\n```\n\n## Methods\n\n### constructor(options : Object)\n\nCreates a new `GLTFBuilder` instance.\n\n### encodeSync(options : Object) : ArrayBuffer\n\nCombines your added JSON data structures (in extras, extensions etc) with any generated JavaScript and any binary subchunks, into a single GLB encoded `ArrayBuffer` that can be written directly to file.\n\n- `options.DracoWriter` - To enable DRACO encoding, the application needs to import and supply the `DracoWriter` _writer object_.\n- `options.DracoLoader` - To enable DRACO encoding, the application needs to import and supply the `DracoLoader` _loader object_.\n\nNote: `encodeSync()` is a one time operation. It should only be called once all data and binary buffers have been added to the builder.\n\n### encodeAsGLBWithJSON(options : Object) : Object\n\nA version of `encode` that returns the final arrayBuffer together with the generated JSON. Note that the returned `arrayBuffer` contains the JSON and is identical to the `encodeAsGLB`.\n\n### setApplicationData(key : String, data : any [, options: Object])\n\nStores the supplied `data` in the given top-level field given by `key`.\n\n- `options.packTypedArrays` - Packs typed arrays into the binary chunk\n- `options.flattenArrays` - Pack (and flatten nested) standard JavaScript arrays into the binary chunk.\n\n### setExtraData(key : String, data : any [, options: Object])\n\nPopulates (merges into) the top-level glTF `extras` field, which the glTF specification reserves for application specific data.\n\n- `options.packTypedArrays` - Packs typed arrays into the binary chunk\n- `options.flattenArrays` - Pack (and flatten nested) standard JavaScript arrays into the binary chunk.\n\n### addExtension(extensionName : String, extension : any [, options: Object])\n\nAdds a top-level glTF extension object, and marks it as used.\n\n- `options.packTypedArrays` - Packs typed arrays into the binary chunk\n- `options.flattenArrays` - Pack (and flatten nested) standard JavaScript arrays into the binary chunk.\n\n### addRequiredExtension(extensionName : String, extension : any [, options: Object])\n\nAdds a top-level glTF extension object, and marks it as used and required.\n\nNote: If possible, use `addExtension` instead of `addRequiredExtension`. It is recommended to avoid using required extensions if possible, as they can reduce the ability to use glTF tools on the resulting file.\n\n- `options.packTypedArrays` - Packs typed arrays into the binary chunk\n- `options.flattenArrays` - Pack (and flatten nested) standard JavaScript arrays into the binary chunk.\n\n### isImage(imageData)\n\nReturns `true` if the binary data represents a well-known binary image format.\n\nNote: This is a utility that is provided to make it easier for decoders to choose whether a binary chunk of data should be stored as an \"image\" or a \"buffer\".\n\n### addBuffer(typedArray : TypedArray, accessor = {size: 3} : Object) : Number\n\nAdds one binary array intended to be loaded back as a WebGL buffer.\n\n- `typedArray` -\n- `accessor` - {size, type, ...}.\n\nType is autodeduced from the type of the typed array.\n\nThe binary data will be added to the GLB BIN chunk, and glTF `bufferView` and `accessor` fields will be populated.\n\n### addImage(typedArray: TypedArray) : Number\n\nAdds a glTF image. The binary image data will be added to the GLB BIN chunk, and glTF `bufferView` and `image` fields will be populated.\n\n### addMesh(attributes: Object [, indices : TypedArray [, mode = 4 : Number ]]) : Number\n\nAdds a glTF mesh. The glTF Mesh will contain one primitive with the supplied attributes.\n\n### addCompressedMesh(attributes: Object [, indices : TypedArray [, mode = 4 : Number ]]) : Number\n\nAdds a glTF mesh. The glTF Mesh will contain one primitive with the supplied attributes, compressed using DRACO compression.\n\n### addPointCloud(attributes: Object) : Number\n\nAdds a glTF mesh. The glTF Mesh will contain one primitive with the supplied attributes, representing a point cloud (no `indices`, mode will default to `0` etc).\n\n### addCompressedPointCloud(attributes: Object) : Number\n\nAdds a glTF mesh. The glTF Mesh will contain one primitive with the supplied attributes, representing a point cloud (no `indices`, mode will default to `0` etc). The point cloud will be compressed using DRACO compression.\n","slug":"docs/api-reference/deprecated/gltf-builder","title":"GLTFBuilder (Deprecated)"},{"excerpt":"GLBParser (Deprecated) This class will be removed in v2.0. Use the  or the  class instead. The  class lets the application access data…","rawMarkdownBody":"# GLBParser (Deprecated)\n\n> This class will be removed in v2.0. Use the `GLBLoader` or the `GLTFScenegraph` class instead.\n\nThe `GLBParser` class lets the application access data encoded in a GLB binary \"envelope\". Most applications would use the `glTFParser` class instead (which uses the `GLBParser` class under the hood to parse GLB-encoded glTF files).\n\nHowever, the GLB encoding can potentially also be used independently to save mixed JSON and binary data, in which case having access to the `GLBParser` class can be helpful.\n\nReferences:\n\n- For more information, see [GLB and GLB support](docs/) in the Developer's Guide.\n\n## Usage\n\n```js\nimport {GLBParser} from '@loaders.gl/gltf';\nimport {load} from '@loaders.gl/core';\n\n// Create a parser\nconst glbParser = new GLBParser();\n\n// Load and parse a file\nconst GLB_BINARY = await load(...);\nglbParser.parse(GLB_BINARY);\n\n// Get the complete GLB JSON structure\nconst gltfJson = glbParser.getJSON();\n\n// Get specific fields from the JSON structure\nconst appData = glbParser.getApplicationData('customData');\n```\n\n## Methods\n\n### constructor(options : Object)\n\nCreates a new `GLBParser` instance.\n\n### parse(arrayBuffer : ArrayBuffer) : Object\n\nParses an in-memory, GLB formatted `ArrayBuffer` into:\n\n- `arrayBuffer` - just returns the input array buffer\n- `binaryByteOffset` - offset to the first byte in the binary chunk\n- `json` - a JavaScript \"JSON\" data structure with inlined binary data fields.\n","slug":"docs/api-reference/deprecated/glb-parser","title":"GLBParser (Deprecated)"},{"excerpt":"Tile3DHeader (Experimental) The 3D tile loaders are still under development. If you are interested in early access, please open an issue…","rawMarkdownBody":"# Tile3DHeader (Experimental)\n\n> The 3D tile loaders are still under development. If you are interested in early access, please open an issue.\n\nClass that simplified access to data inside a tile in a `Tileset3D`.\n\nNotes:\n\n- When a tile is first created, its content is not loaded; the content is loaded on-demand when needed based on the view.\n\n## Fields\n\n### tileset : Tileset3D\n\nThe tileset containing this tile.\n\n### content : Tile3DContent\n\nThe tile's content. This represents the actual tile's payload,\nnot the content's metadata in the tileset JSON file.\n\n### boundingVolume : TileBoundingVolume\n\nGet the tile's bounding volume.\n\n### contentBoundingVolume : TileBoundingVolume\n\nGet the bounding volume of the tile's contents. This defaults to the\ntile's bounding volume when the content's bounding volume is\n`undefined`.\n\n### boundingSphere : BoundingSphere\n\nGet the bounding sphere derived from the tile's bounding volume.\n\n### extras : any\n\nReturns the `extras` property in the tileset JSON for this tile, which contains application specific metadata.\nReturns `undefined` if `extras` does not exist.\n\nSee [Extras in the 3D Tiles specification](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#specifying-extensions-and-application-specific-extras)\n\n### contentAvailable : Boolean\n\nDetermines if the tile has available content to render. `true` if the tile's\ncontent is ready or if it has expired content that renders while new content loads; otherwise,\n`false`.\n\n### contentReady : Boolean\n\nDetermines if the tile's content is ready. This is automatically `true` for\ntile's with empty content.\n\n### contentUnloaded : Boolean\n\nDetermines if the tile's content has not be requested. `true` if tile's\ncontent has not be requested; otherwise, `false`.\n\n\n### contentExpired : Boolean\n\nDetermines if the tile's content is expired. `true` if tile's\ncontent is expired; otherwise, `false`.\n\n### contentFailed : Boolean\n\nDetermines if the tile's content failed to load. `true` if the tile's\ncontent failed to load; otherwise, `false`.\n\n### contentReadyToProcessPromise : Promise\n\nGets the promise that will be resolved when the tile's content is ready to process.\nThis happens after the content is downloaded but before the content is ready\nto render.\n\nThe promise remains `undefined` until the tile's content is requested.\n\n### contentReadyPromise : Promise.Tile3DContent\n\nGets the promise that will be resolved when the tile's content is ready to render.\n\nThe promise remains `undefined` until the tile's content is requested.\n\n### commandsLength : Number\n\nEstimates the number of draw commands used by this tile.\n\n## Methods\n\n### constructor(tileset, baseResource, header, parent)\n\nNote: Do not construct this directly, instead access tiles through {@link Tileset3D#tileVisible}.\n\n### destroy()\n\nReleases resources managed by this tile.\n\n### getScreenSpaceError(frameState, useParentGeometricError) : Number\n\nGet the tile's screen space error.\n\n### updateVisibility(frameState) : void\n\nUpdate the tile's visibility.\n\n### requestContent()\n\nRequests the tile's content.\n\nThe request may not be made if the Request Scheduler can't prioritize it.\n\n### unloadContent()\n\nUnloads the tile's content.\n\n### visibility(frameState, parentVisibilityPlaneMask)\n\nDetermines whether the tile's bounding volume intersects the culling volume.\n\n- FrameState frameState The frame state.\n- Number parentVisibilityPlaneMask The parent's plane mask to speed up the visibility check.\n\nReturns\n{Number} A plane mask as described above in {@link CullingVolume#computeVisibilityWithPlaneMask}.\n\n\n### contentVisibility(frameState)\n\nAssuming the tile's bounding volume intersects the culling volume, determines\nwhether the tile's content's bounding volume intersects the culling volume.\n- FrameState frameState The frame state.\n\nReturns\n{Intersect} The result of the intersection: the tile's content is completely outside, completely inside, or intersecting the culling volume.\n\n### distanceToTile(frameState) : Number\n\nComputes the (potentially approximate) distance from the closest point of the tile's bounding volume to the camera.\n- FrameState frameState The frame state.\n\nReturns\n{Number} The distance, in meters, or zero if the camera is inside the bounding volume.\n\n### distanceToTileCenter(frameState)\n\nComputes the distance from the center of the tile's bounding volume to the camera.\n- FrameState frameState The frame state.\n\nReturns\n{Number} The distance, in meters.\n\n### insideViewerRequestVolume(frameState) : Boolean\n\nChecks if the camera is inside the viewer request volume.\n\n- FrameState frameState The frame state.\n\nReturns\n{Boolean} Whether the camera is inside the volume.\n\n### createBoundingVolume(boundingVolumeHeader, transform, result) {\n\nCreate a bounding volume from the tile's bounding volume header.\n\n- Object boundingVolumeHeader The tile's bounding volume header.\n- Matrix4 transform The transform to apply to the bounding volume.\n- TileBoundingVolume [result] The object onto which to store the result.\n\n\nReturns\n{TileBoundingVolume} The modified result parameter or a new TileBoundingVolume instance if none was provided.\n\n\n### updateTransform(parentTransform)\n\nUpdate the tile's transform. The transform is applied to the tile's bounding volumes.\n\n### transform\n\nThe local transform of this tile.\n@type {Matrix4}\n\n### computedTransform\n\nThe final computed transform of this tile.\n@type {Matrix4}\n\nThe error, in meters, introduced if this tile is rendered and its children are not.\n\n\n### geometricError : number\n\nThis is used to compute screen space error, i.e., the error measured in pixels.\n\n### refinement : 3DTileRefine\n\nSpecifies the type of refinement that is used when traversing this tile for rendering.\n\n### children : Tile3dHeader[]\n\nGets the tile's children.\n\n### parent : Tile3DHeader | null;\n\nThis tile's parent or `undefined` if this tile is the root.\n\nWhen a tile's content points to an external tileset JSON file, the external tileset's root tile's parent is not `undefined`; instead, the parent references the tile (with its content pointing to an external tileset JSON file) as if the two tilesets were merged.\n\n\n### hasEmptyContent : boolean\nWhen `true`, the tile has no content.\n\n### hasTilesetContent : boolean\n\nWhen `true`, the tile's content points to an external tileset.\n\nThis is `false` until the tile's content is loaded.\n\n\n\n### expireDuration : Number\n\nThe time in seconds after the tile's content is ready when the content expires and new content is requested.\n\n### expireDate : JulianDate\n\nThe date when the content expires and new content is requested.\n\n### lastStyleTime ; Number\n\nThe time when a style was last applied to this tile.\n\nMarks whether the tile's children bounds are fully contained within the tile's bounds\n\n### optimChildrenWithinParent : Tile3DOptimizationHint = Tile3DOptimizationHint.NOT_COMPUTED;\n\nTracks if the tile's relationship with a ClippingPlaneCollection has changed with regards\nto the ClippingPlaneCollection's state.\n","slug":"docs/api-reference/3d-tile-loaders/tile-3d-header","title":"Tile3DHeader (Experimental)"},{"excerpt":"ImageLoader An image loader that works under both Node.js and the browser. Options   Remarks While generic, the  is designed with WebGL…","rawMarkdownBody":"# ImageLoader\n\nAn image loader that works under both Node.js and the browser.\n\n## Options\n\n- `image`\n- `options.mimeType`\n\n## Remarks\n\n- While generic, the `ImageLoader` is designed with WebGL applications in mind, ensuring that loaded image data can be used to create a `WebGLTexture` both in the browser and in headless gl under Node.js\n- Node.js support requires import `@loaders.gl/polyfills` before installing this module.\n","slug":"docs/api-reference/image-loaders/image-loader","title":"ImageLoader"},{"excerpt":"Tileset3D (Experimental) The 3D tiles loaders are still under development. If you are interested in early access, please open an issue. A 3D…","rawMarkdownBody":"# Tileset3D (Experimental)\n\n> The 3D tiles loaders are still under development. If you are interested in early access, please open an issue.\n\nA [3D Tiles tileset](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification), used for streaming massive heterogeneous 3D geospatial datasets.\n\n## Usage\n\n```js\nimport {Tileset3DLoader, Tileset3D} from '^loaders.gl/3d-tiles';\nconst TILESET_URI = 'http://localhost:8002/tilesets/Seattle/tileset.json';\nconst tilesetJson = await parse(fetch(TILESET_URI), Tileset3DLoader);\nconst tileset = new Tileset3D(tilesetJson);\n```\n\n```js\nconst tileset = new Tileset3D( );\nconsole.log(`Maximum building height: ${tileset.properties.height.maximum}`);\nconsole.log(`Minimum building height: ${tileset.properties.height.minimum}`);\n```\n\nCommon setting for the skipLevelOfDetail optimization\n\n```js\nimport {Tileset3D} from '^loaders.gl/3d-tiles';\nconst tileset = new Tileset3D({\n  url: 'http://localhost:8002/tilesets/Seattle/tileset.json',\n  skipLevelOfDetail: true,\n  baseScreenSpaceError: 1024,\n  skipScreenSpaceErrorFactor: 16,\n  skipLevels: 1,\n  immediatelyLoadDesiredLevelOfDetail: false,\n  loadSiblings: false,\n  cullWithChildrenBounds: true\n});\n```\n\nCommon settings for the dynamicScreenSpaceError optimization\n\n```js\nimport {Tileset3D} from '^loaders.gl/3d-tiles';\nconst tileset = new Tileset3D({\n  url: 'http://localhost:8002/tilesets/Seattle/tileset.json',\n  dynamicScreenSpaceError: true,\n  dynamicScreenSpaceErrorDensity: 0.00278,\n  dynamicScreenSpaceErrorFactor: 4.0,\n  dynamicScreenSpaceErrorHeightFalloff: 0.25\n});\n```\n\n## Methods\n\n### constructor(options)\n\nNotes: The tileset must be 3D Tiles version 0.0 or 1.0.\n\n`options` Object with the following properties:\n\n- `options.url` (`Resource|String|Promise.Resource|Promise.String`) The url to a tileset JSON file.\n- `options.show`=`true` (`Boolean`) - Determines if the tileset will be shown.\n- `options.modelMatrix`=`Matrix4.IDENTITY` (`Matrix4`) - A 4x4 transformation matrix that transforms the tileset's root tile.\n- `options.maximumScreenSpaceError`=`16`] (`Number`) - The maximum screen space error used to drive level of detail refinement.\n- `options.maximumMemoryUsage`=`512`] (`Number`) - The maximum amount of memory in MB that can be used by the tileset.\n- `options.cullWithChildrenBounds`=`true`] (`Boolean`) - Optimization option. Whether to cull tiles using the union of their children bounding volumes.\n- `options.dynamicScreenSpaceError`=`false`] (`Boolean`) - Optimization option. Reduce the screen space error for tiles that are further away from the camera.\n- `options.dynamicScreenSpaceErrorDensity`=`0.00278`] (`Number`) - Density used to adjust the dynamic screen space error, similar to fog density.\n- `options.dynamicScreenSpaceErrorFactor`=`4.0`] (`Number`) - A factor used to increase the computed dynamic screen space error.\n- `options.dynamicScreenSpaceErrorHeightFalloff`=`0.25` (`Number`) - A ratio of the tileset's height at which the density starts to falloff.\n- `options.skipLevelOfDetail`=`true` (`Boolean`) - Optimization option. Determines if level of detail skipping should be applied during the traversal.\n- `options.baseScreenSpaceError`=`1024` (`Number`) - When `skipLevelOfDetail` is `true`, the screen space error that must be reached before skipping levels of detail.\n- `options.skipScreenSpaceErrorFactor`=`16` (`Number`) - When `skipLevelOfDetail` is `true`, a multiplier defining the minimum screen space error to skip. Used in conjunction with `skipLevels` to determine which tiles to load.\n- `options.skipLevels`=`1` (`Number`) - When `skipLevelOfDetail` is `true`, a constant defining the minimum number of levels to skip when loading tiles. When it is 0, no levels are skipped. Used in conjunction with `skipScreenSpaceErrorFactor` to determine which tiles to load.\n- `options.immediatelyLoadDesiredLevelOfDetail`=`false` (`Boolean`) - When `skipLevelOfDetail` is `true`, only tiles that meet the maximum screen space error will ever be downloaded. Skipping factors are ignored and just the desired tiles are loaded.\n- `options.loadSiblings`=`false` (`Boolean`) - When `skipLevelOfDetail` is `true`, determines whether siblings of visible tiles are always downloaded during traversal.\n\nRendering Options:\n\n- `options.shadows`=`ShadowMode.ENABLED`] (`ShadowMode`) - Determines whether the tileset casts or receives shadows from each light source.\n- `options.clippingPlanes`= (`ClippingPlaneCollection`) The (`ClippingPlaneCollection`) used to selectively disable rendering the tileset.\n- `options.classificationType` (`ClassificationType`) - Determines whether terrain, 3D Tiles or both will be classified by this tileset. See (`Tileset3D#classificationType`) for details about restrictions and limitations.\n- `options.ellipsoid`=`Ellipsoid.WGS84` (`Ellipsoid`) - The ellipsoid determining the size and shape of the globe.\n- `options.pointCloudShading`] (`Object`) - Options for constructing a (`PointCloudShading`) object to control point attenuation based on geometric error and lighting.\n- `options.imageBasedLightingFactor`=`[1.0, 1.0]` - Scales the diffuse and specular image-based lighting from the earth, sky, atmosphere and star skybox.\n- `options.lightColor`= (Number[3]) - The color and intensity of the sunlight used to shade models.\n- (`Number`) `options.luminanceAtZenith`=`0`. - 5] The sun's luminance at the zenith in kilo candela per meter squared to use for this model's procedural environment map.\n- (`Cartesian3[]`) `options.sphericalHarmonicCoefficients`] The third order spherical harmonic coefficients used for the diffuse color of image-based lighting.\n- (`String`) `options.specularEnvironmentMaps`] A URL to a KTX file that contains a cube map of the specular lighting and the convoluted specular mipmaps.\n\nDebug Options:\n\n- `options.debugFreezeFrame`=`false` (`Boolean`) - For debugging only. Determines if only the tiles from last frame should be used for rendering.\n- `options.debugColorizeTiles`=`false` (`Boolean`) - For debugging only. When true, assigns a random color to each tile.\n- `options.debugWireframe`=`false` (`Boolean`) - For debugging only. When true, render's each tile's content as a wireframe.\n- `options.debugShowBoundingVolume`=`false`](`Boolean`) - For debugging only. When true, renders the bounding volume for each tile.\n- `options.debugShowContentBoundingVolume`=`false` (`Boolean`) - For debugging only. When true, renders the bounding volume for each tile's content.\n- `options.debugShowViewerRequestVolume`=`false` (`Boolean`) - For debugging only. When true, renders the viewer request volume for each tile.\n- `options.debugShowGeometricError`=`false` (`Boolean`) - For debugging only. When true, draws labels to indicate the geometric error of each tile.\n- `options.debugShowRenderingStatistics`=`false` (`Boolean`) - For debugging only. When true, draws labels to indicate the number of commands, points, triangles and features for each tile.\n- `options.debugShowMemoryUsage`=`false` (`Boolean`) - For debugging only. When true, draws labels to indicate the texture and geometry memory in megabytes used by each tile.\n- `options.debugShowUrl`=`false` (`Boolean`) - For debugging only. When true, draws labels to indicate the url of each tile.\n\n### hasExtension(extensionName : String) : Boolean\n\n`true` if the tileset JSON file lists the extension in extensionsUsed; otherwise, `false`.\n^param {String} extensionName The name of the extension to check. \\*\n^returns {Boolean} `true` if the tileset JSON file lists the extension in extensionsUsed; otherwise, `false`.\n\n\n## Option\n\n### dynamicScreenSpaceError\n\n=`false`\n\nOptimization option. Whether the tileset should refine based on a dynamic screen space error. Tiles that are further away will be rendered with lower detail than closer tiles. This improves performance by rendering fewer tiles and making less requests, but may result in a slight drop in visual quality for tiles in the distance.\n\nThe algorithm is biased towards \"street views\" where the camera is close to the ground plane of the tileset and looking at the horizon. In addition results are more accurate for tightly fitting bounding volumes like box and region.\n\n### dynamicScreenSpaceErrorDensity\n\n=`0.00278`\n\nA scalar that determines the density used to adjust the dynamic screen space error (similar to \"fog\"). Increasing this value has the effect of increasing the maximum screen space error for all tiles, but in a non-linear fashion.\n\nThe error starts at 0.0 and increases exponentially until a midpoint is reached, and then approaches 1.0 asymptotically. This has the effect of keeping high detail in the closer tiles and lower detail in the further tiles, with all tiles beyond a certain distance all roughly having an error of 1.0.\n\n\nThe dynamic error is in the range [0.0, 1.0) and is multiplied by `dynamicScreenSpaceErrorFactor` to produce the\nfinal dynamic error. This dynamic error is then subtracted from the tile's actual screen space error.\n\nIncreasing `dynamicScreenSpaceErrorDensity` has the effect of moving the error midpoint closer to the camera.\nIt is analogous to moving fog closer to the camera.\n\n### dynamicScreenSpaceErrorFactor\n\n= 4.0;\n\nA factor used to increase the screen space error of tiles for dynamic screen space error. As this value increases less tiles\nare requested for rendering and tiles in the distance will have lower detail. If set to zero, the feature will be disabled.\n\n### dynamicScreenSpaceErrorHeightFalloff\n\n= 0.25;\n\nA ratio of the tileset's height at which the density starts to falloff. If the camera is below this height the\nfull computed density is applied, otherwise the density falls off. This has the effect of higher density at\nstreet level views.\n\n\nValid values are between 0.0 and 1.0.\n\n# loadProgress : Event\n\nThe event fired to indicate progress of loading new tiles.  This event is fired when a new tile\nis requested, when a requested tile is finished downloading, and when a downloaded tile has been\nprocessed and is ready to render.\n\nThe number of pending tile requests, `numberOfPendingRequests`, and number of tiles\nprocessing, `numberOfTilesProcessing` are passed to the event listener.\n\nThis event is fired at the end of the frame after the scene is rendered.\n\n```js\ntileset.loadProgress.addEventListener(function(numberOfPendingRequests, numberOfTilesProcessing) {\n    if ((numberOfPendingRequests === 0) && (numberOfTilesProcessing === 0)) {\n        console.log('Stopped loading');\n        return;\n    }\n    console.log('Loading: requests: ' + numberOfPendingRequests + ', processing: ' + numberOfTilesProcessing);\n});\n```\n\n### allTilesLoaded : Event\n\nThe event fired to indicate that all tiles that meet the screen space error this frame are loaded. The tileset\nis completely loaded for this view.\n\nThis event is fired at the end of the frame after the scene is rendered.\n\n### initialTilesLoaded : Event\n\nThe event fired to indicate that all tiles that meet the screen space error this frame are loaded. This event\nis fired once when all tiles in the initial view are loaded.\n\nThis event is fired at the end of the frame after the scene is rendered.\n\n\n```js\ntileset.initialTilesLoaded.addEventListener(function() {\n    console.log('Initial tiles are loaded');\n});\n```\n\n### tileLoad : Event\n\nThe event fired to indicate that a tile's content was loaded.\n\nThe loaded `Tile3D` is passed to the event listener.\n\nThis event is fired during the tileset traversal while the frame is being rendered\nso that updates to the tile take effect in the same frame.  Do not create or modify\nentities or primitives during the event listener.\n\n```js\n    tileset.tileLoad.addEventListener(function(tile) {\n        console.log('A tile was loaded.');\n    });\n```\n\n### tileUnload : Event\n\nThe event fired to indicate that a tile's content was unloaded.\n\nThe unloaded `Tile3D` is passed to the event listener.\n\nThis event is fired immediately before the tile's content is unloaded while the frame is being\nrendered so that the event listener has access to the tile's content.  Do not create\nor modify entities or primitives during the event listener.\n\n```js\ntileset.tileUnload.addEventListener(function(tile) {\n    console.log('A tile was unloaded from the cache.');\n});\n```\n *\nsee Tileset3D#maximumMemoryUsage\nsee Tileset3D#trimLoadedTiles\n\n\n### tileset.tileFailed\n\nThe event fired to indicate that a tile's content failed to load.\n\nIf there are no event listeners, error messages will be logged to the console.\n\nThe error object passed to the listener contains two properties:\n<ul>\n<li>`url`: the url of the failed tile.</li>\n<li>`message`: the error message.</li>\n</ul>\n *\n^type {Event}\n^default new Event()\n *\n```js\nthis.tileFailed = new Event();\n    console.log('An error occurred loading tile: ' + error.url);\n    console.log('Error: ' + error.message);\n});\n```\n */\n\n/**\nThis event fires once for each visible tile in a frame.  This can be used to manually\nstyle a tileset.\n\nThe visible 3DTile is passed to the event listener.\n\nThis event is fired during the tileset traversal while the frame is being rendered\nso that updates to the tile take effect in the same frame.  Do not create or modify\nentities or primitives during the event listener.\n *\n^type {Event}\n^default new Event()\n *\n^example\n```js\ntileset.tileVisible.addEventListener(function(tile) {\n    if (tile.content instanceof Batched3DModel3DTileContent) {\n        console.log('A Batched 3D Model tile is visible.');\n    }\n});\n```\n\n### skipLevelOfDetail : Boolean\n\nDefault: true\n\nOptimization option. Determines if level of detail skipping should be applied during the traversal.\n\nThe common strategy for replacement-refinement traversal is to store all levels of the tree in memory and require\nall children to be loaded before the parent can refine. With this optimization levels of the tree can be skipped\nentirely and children can be rendered alongside their parents. The tileset requires significantly less memory when\nusing this optimization.\n\n\n### baseScreenSpaceError : Number\n\nDefault: 1024\n\nThe screen space error that must be reached before skipping levels of detail.\n\nOnly used when `skipLevelOfDetail` is `true`.\n\n### skipScreenSpaceErrorFactor : Number\n\nDefault: 16\n\nMultiplier defining the minimum screen space error to skip.\nFor example, if a tile has screen space error of 100, no tiles will be loaded unless they\nare leaves or have a screen space error `<= 100 / skipScreenSpaceErrorFactor`.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### skipLevels\n\nDefault: 1\n\nConstant defining the minimum number of levels to skip when loading tiles. When it is 0, no levels are skipped.\nFor example, if a tile is level 1, no tiles will be loaded unless they are at level greater than 2.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### immediatelyLoadDesiredLevelOfDetail : false\n\nWhen true, only tiles that meet the maximum screen space error will ever be downloaded.\nSkipping factors are ignored and just the desired tiles are loaded.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### loadSiblings: false\n\nDetermines whether siblings of visible tiles are always downloaded during traversal.\nThis may be useful for ensuring that tiles are already available when the viewer turns left/right.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### asset : Object (readonly)\n\nGets the tileset's asset object property, which contains metadata about the tileset.\n\nSee the [asset schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-asset) in the 3D Tiles spec for the full set of properties.\n\n### properties\n\nGets the tileset's properties dictionary object, which contains metadata about per-feature properties.\n\nSee the [properties schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-properties) in the 3D Tiles spec for the full set of properties.\n\nsee Cesium3DTileFeature#getProperty\nsee Cesium3DTileFeature#setProperty\n\n### ready\n\nWhen `true`, the tileset's root tile is loaded and the tileset is ready to render.\nThis is set to `true` right before `Tileset3D.readyPromise` is resolved.\n\n### readyPromise\n\nGets the promise that will be resolved when the tileset's root tile is loaded and the tileset is ready to render.\n\nThis promise is resolved at the end of the frame before the first frame the tileset is rendered in.\n\n\n```js\ntileset.readyPromise.then(function(tileset) {\n    // tile.properties is not defined until readyPromise resolves.\n    var properties = tileset.properties;\n    if (defined(properties)) {\n        for (var name in properties) {\n            console.log(properties[name]);\n        }\n    }\n});\n```\n\n### tilesLoaded : boolean (readonly)\n\nWhen `true`, all tiles that meet the screen space error this frame are loaded. The tileset is\ncompletely loaded for this view.\n\nSee Tileset3D#allTilesLoaded\n\n\n### url : String (readonly)\n\nThe url to a tileset JSON file.\n\n### basePath : String (readonly) (deprecated)\n\nThe base path that non-absolute paths in tileset JSON file are relative to.\n\n### maximumScreenSpaceError\n\nThe maximum screen space error used to drive level of detail refinement. This value helps determine when a tile refines to its descendants, and therefore plays a major role in balancing performance with visual quality.\n\n\nA tile's screen space error is roughly equivalent to the number of pixels wide that would be drawn if a sphere with a\nradius equal to the tile's <b>geometric error</b> were rendered at the tile's position. If this value exceeds\n`maximumScreenSpaceError` the tile refines to its descendants.\n\nDepending on the tileset, `maximumScreenSpaceError` may need to be tweaked to achieve the right balance. Higher values provide better performance but lower visual quality.\n *\n\n### maximumMemoryUsage : Number\n\n^default 16\n *\n^exception `maximumScreenSpaceError` must be greater than or equal to zero.\n\nThe maximum amount of GPU memory (in MB) that may be used to cache tiles. This value is estimated from\ngeometry, textures, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\n\nTiles not in view are unloaded to enforce this.\n\nIf decreasing this value results in unloading tiles, the tiles are unloaded the next frame.\n\nIf tiles sized more than `maximumMemoryUsage` are needed\nto meet the desired screen space error, determined by `Tileset3D.maximumScreenSpaceError `,\nfor the current view, then the memory usage of the tiles loaded will exceed\n`maximumMemoryUsage`.  For example, if the maximum is 256 MB, but\n300 MB of tiles are needed to meet the screen space error, then 300 MB of tiles may be loaded.  When\nthese tiles go out of view, they will be unloaded.\n\n^default 512\n *\n^exception `maximumMemoryUsage` must be greater than or equal to zero.\n^see Tileset3D#totalMemoryUsageInBytes\n\n### root : Tile3DHeader\n\nThe root tile header.\n\n\n### boundingSphere : BoundingSphere\n\nThe tileset's bounding sphere.\n\n\n```js\nvar tileset = viewer.scene.primitives.add(new Tileset3D({\nurl : 'http://localhost:8002/tilesets/Seattle/tileset.json'\n}));\n\ntileset.readyPromise.then(function(tileset) {\n// Set the camera to view the newly added tileset\nviewer.camera.viewBoundingSphere(tileset.boundingSphere, new HeadingPitchRange(0, -0.5, 0));\n});\n```\n\n### modelMatrix : Matrix4\n\nA 4x4 transformation matrix that transforms the entire tileset.\n\n```js\n// Adjust a tileset's height from the globe's surface.\nvar heightOffset = 20.0;\nvar boundingSphere = tileset.boundingSphere;\nvar cartographic = Cartographic.fromCartesian(boundingSphere.center);\nvar surface = Cartesian3.fromRadians(cartographic.longitude, cartographic.latitude, 0.0);\nvar offset = Cartesian3.fromRadians(cartographic.longitude, cartographic.latitude, heightOffset);\nvar translation = Cartesian3.subtract(offset, surface, new Cartesian3());\ntileset.modelMatrix = Matrix4.fromTranslation(translation);\n```\n\n\n### timeSinceLoad : Number\n\nReturns the time, in milliseconds, since the tileset was loaded and first updated.\n\n\n### maximumMemoryUsage : Number\n\n### totalMemoryUsageInBytes : Number\n\nThe total amount of GPU memory in bytes used by the tileset. This value is estimated from\ngeometry, texture, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\n### statistics\n\n\n### classificationType (Experimental) readonly\n\nDetermines whether terrain, 3D Tiles or both will be classified by this tileset.\n\n\nThis option is only applied to tilesets containing batched 3D models, geometry data, or vector data. Even when undefined, vector data and geometry data\nmust render as classifications and will default to rendering on both terrain and other 3D Tiles tilesets.\n\nWhen enabled for batched 3D model tilesets, there are a few requirements/limitations on the glTF:\n<ul>\n    <li>POSITION and _BATCHID semantics are required.</li>\n    <li>All indices with the same batch id must occupy contiguous sections of the index buffer.</li>\n    <li>All shaders and techniques are ignored. The generated shader simply multiplies the position by the model-view-projection matrix.</li>\n    <li>The only supported extensions are CESIUM_RTC and WEB3D_quantized_attributes.</li>\n    <li>Only one node is supported.</li>\n    <li>Only one mesh per node is supported.</li>\n    <li>Only one primitive per mesh is supported.</li>\n</ul>\n\nThis feature is using part of the 3D Tiles spec that is not final and is subject to change without the standard deprecation policy.\n\n\n### ellipsoid : Ellipsoid\n\nGets an ellipsoid describing the shape of the globe.\n\nReturns the `extras` property at the top-level of the tileset JSON, which contains application specific metadata.\nReturns `undefined` if `extras` does not exist.\n\nException The tileset is not loaded. Use Tileset3D.readyPromise or wait for Tileset3D.ready to be true.\n\nSee [Extras](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#specifying-extensions-and-application-specific-extras) in the 3D Tiles specification.}\n\n\n### loadJson\n\nProvides a hook to override the method used to request the tileset json\nuseful when fetching tilesets from remote servers\n\n^param {Resource|String} tilesetUrl The url of the json file to be fetched\n^returns {Promise.Object} A promise that resolves with the fetched json data\n\n```js\nTileset3D.loadJson = function(tilesetUrl) {\n  var resource = Resource.createIfNeeded(tilesetUrl);\n  return resource.fetchJson();\n};\n```\n\n### loadTileset\n\nLoads the main tileset JSON file or a tileset JSON file referenced from a tile.\n\n\n\nUnloads all tiles that weren't selected the previous frame. This can be used to\nexplicitly manage the tile cache and reduce the total number of tiles loaded below\n`Tileset3D.maximumMemoryUsage`.\n\nTile unloads occur at the next frame to keep all the WebGL delete calls\nwithin the render loop.\n\n### isDestroyed() : Boolean\n\nReturns true if this object was destroyed; otherwise, false.\n\nIf this object was destroyed, it should not be used; calling any function other than\n`isDestroyed` will result in an exception.\n\n^returns `Boolean`: `true` if this object was destroyed; otherwise, `false`.\n\n### destroy()\n\nDestroys the WebGL resources held by this object. Destroying an object allows for deterministic\nrelease of WebGL resources, instead of relying on the garbage collector to destroy this object.\n\nOnce an object is destroyed, it should not be used; calling any function other than `isDestroyed` will result in an exception. Therefore, assign the return value `undefined` to the object as done in the example.\n\nWxception This object was destroyed, i.e., destroy() was called.\n\n","slug":"docs/api-reference/3d-tile-loaders/tileset-3d","title":"Tileset3D (Experimental)"},{"excerpt":"Tile3DLoader (Experimental) The 3D tile loaders are still under development. If you are interested in early access, please open an issue…","rawMarkdownBody":"# Tile3DLoader (Experimental)\n\n> The 3D tile loaders are still under development. If you are interested in early access, please open an issue.\n\nParses a [3D tile](https://github.com/AnalyticalGraphicsInc/3d-tiles). glTF file into a hirearchical scenegraph description that can be used to instantiate an actual Scenegraph in most WebGL libraries. Can load both binary `.glb` files and JSON `.gltf` files.\n\n| Loader                | Characteristic                                                                                                    |\n| --------------------- | ----------------------------------------------------------------------------------------------------------------- |\n| File Extensions       | `.b3dm`,`.i3dm`, `.pnts`, `.cmpt`                                                                                 |\n| File Types            | Binary (with linked assets)                                                                                       |\n| File Format           | [glTF](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#tile-format-specifications)    |\n| Format Category       | 3D Tile                                                                                                           |\n| Parser Type           | Asynchronous (Synchronous w/ limited functionality)                                                               |\n| Worker Thread Support | No                                                                                                                |\n| Streaming Support     | No (not for invididual tiles, however tilesets are streamed by loading only the tiles needed for the current view |\n\n## Usage\n\n```\nimport {load} from '@loaders.gl/core';\nimport {Tile3DLoader} from '@loaders.gl/3d-tiles';\nconst gltf = await load(url, Tile3DLoader);\n```\n\nTo decompress tiles containing Draco compressed glTF models or Draco compressed point clouds:\n\n```\nimport {load} from '@loaders.gl/core';\nimport {Tile3DLoader} from '@loaders.gl/3d-tiles';\nimport {DracoLoader} from '@loaders.gl/draco';\nconst gltf = load(url, Tile3DLoader, {DracoLoader, decompress: true});\n```\n\n## Options\n\n- `DracoEncoder` - supply this to enable decoding of Draco compressed meshes. `import {DracoEncoder} from '@loaders.gl/draco'`\n\n## Options\n\n| Option                 | Default     | Description                                                                                      |\n| ---------------------- | ----------- | ------------------------------------------------------------------------------------------------ |\n| `fetchLinkedResources` | `true`      | Fetch any linked .BIN files, decode base64 encoded URIS. Only supported in asynchronous parsing. |\n| `fetch`                | `fetchFile` | Function used to fetch linked resources                                                          |\n| `decompress`           | `true`      | Decompress Draco compressed meshes (if DracoLoader available)                                    |\n| `DracoLoader`          | `null`      | Supply to enable decoding of Draco compressed meshes.                                            |\n| `postProcess`          | `false`     | Perform additional post processing to simplify use in WebGL libraries                            |\n| `createImages`         | `false`     | Create image objects from loaded image data                                                      |\n\n## Structure of Loaded Data\n\nReturns a JSON object with \"embedded\" binary data in the form of typed javascript arrays.\n\nWhen parsed asynchronously (i.e. not using `parseSync`):\n\n- linked binary resources will be loaded and resolved (if url is available).\n- base64 encoded binary data inside the JSON payload will be decoded\n\n## Attributions\n\nThe `Tile3DLoader` is a fork of 3d tile related code in Cesium (https://github.com/AnalyticalGraphicsInc/cesium) under Apache 2 License, in collabration with Sean Lilley, Josh Lawrence and Patrick Cozzi at Cesium.\n","slug":"docs/api-reference/3d-tile-loaders/tile-3d-loader","title":"Tile3DLoader (Experimental)"},{"excerpt":"Image Utilities A set of functions to help determine the type and size of binary images. Usage Functions isImage(imageData : ArrayBuffer…","rawMarkdownBody":"# Image Utilities\n\nA set of functions to help determine the type and size of binary images.\n\n## Usage\n\n```js\nconst arrayBuffer = await fetchFile(imageUrl).then(response => response.arrayBuffer());\n\nconst mimeType = getImageMIMEType(arrayBuffer);\nconst {width, height} = getImageSize(arrayBuffer, mimeType);\n```\n\n## Functions\n\n### isImage(imageData : ArrayBuffer [, mimeType : String]) : Boolean\n\nParameters:\n- `imageData`: Binary encoded image data.\n- `mimeType`: A MIME type string.\n\nReturns `true` if the binary data represents a known binary image format or matches the supplied `mimeType`.\n\nParameters:\n- `mimeType`: If supplied, checks if the image is of that type. If not supplied, returns `true` if imageData corresponds to a know supported image format.\n\n### getImageMIMEType(imageData : ArrayBuffer) : String | null\n\nParameters:\n- `imageData`: Binary encoded image data.\n\nReturns:\n- the MIME type of the image represented by the data, or `null` if it could not be identified.\n\n### getImageSize(imageData : ArrayBuffer [, mimeType : String]) : Object\n\nExtracts the size of the image in `imageData`. If `mimeType` is supplied, assumes the image is of that type. If not supplied, first attempts to auto deduce the image format (see `getImageMIMEType`).\n\nParameters:\n- `imageData`: Binary encoded image data.\n- `mimeType`: A MIME type string.\n\nReturns:\n- an object with fields containing the size of the image represented by the data.\n\n```js\n{\n  width: Number,\n  height: Number\n}\n```\n\nThrows:\n- if image is not in a supported format.\n\n### getImageMetadata(imageData : ArrayBuffer [, mimeType : String]) : Object\n\nExtracts the size of the image in `imageData`. If `mimeType` is supplied, assumes the image is of that type. If not supplied, first attempts to auto deduce the image format (see `getImageMIMEType`).\n\nParameters:\n- `imageData`: Binary encoded image data.\n- `mimeType`: A MIME type string.\n\nReturns:\n- an object with fields containing the size and mimeType of the image represented by the data.\n\n```js\n{\n  width: Number,\n  height: Number,\n  mimeType: String\n}\n```\n\nThrows:\n- if image is not in a supported format.\n\n## Supported Formats\n\nCurrently supported image formats and MIME types are:\n\n| Format | MIME Type    |\n| ---    | ---          |\n| PNG    | `image/png`  |\n| JPEG   | `image/jpeg` |\n| GIF    | `image/gif`  |\n| BMP    | `image/bmp`  |\n","slug":"docs/api-reference/image-loaders/image-utilities","title":"Image Utilities"},{"excerpt":"ImageWriter The  class can encode an image into  both under browser and Node.js encodeImage(image : any, options : Object)  - This can be an…","rawMarkdownBody":"# ImageWriter\n\nThe `ImageWriter` class can encode an image into `ArrayBuffer` both under browser and Node.js\n\n# encodeImage(image : any, options : Object)\n\n- `image` - This can be an HTML image, a Canvas, or a ...\n- `options.mimeType`\n\n## MIME types\n\nSupported image types (MIME types) depends on the environment. Typically PNG and JPG are supported.\n","slug":"docs/api-reference/image-loaders/image-writer","title":"ImageWriter"},{"excerpt":"loadImage Functions loadImage(url : String , options : Object) : Image / HTMLImageElement This is a minimal basic image loading function…","rawMarkdownBody":"# loadImage\n\n## Functions\n\n### loadImage(url : String [, options : Object]) : Image / HTMLImageElement\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/browser-only-red.svg?style=flat-square\" alt=\"browser only\" />\n</p>\n\nThis is a minimal basic image loading function that only works in the browser main threaqd. For image loading and writing that works across both browser and node, refer to the `@loaders.gl/images` module.\n\n`options.crossOrigin` - Provides control of the requests cross origin field.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n","slug":"docs/api-reference/image-loaders/load-image","title":"loadImage"},{"excerpt":"Binary Utilities loaders.gl provides a set of functions to simplify working with binary data. There are a couple of different ways to deal…","rawMarkdownBody":"# Binary Utilities\n\nloaders.gl provides a set of functions to simplify working with binary data. There are a couple of different ways to deal with binary data in the JavaScript APIs for browser and Node.js, and some small but annoying \"gotchas\" that can trip up programmers when working with binary data.\n\n## Usage\n\n```js\nimport {toArrayBuffer} from '@loaders.gl/core';\n```\n\n## Functions\n\n### toArrayBuffer(binaryData : \\*) : ArrayBuffer\n\n\"Repackages\" a binary data in non-array-buffer form as an `ArrayBuffer`.\n\n- binaryData - ArrayBuffer, Buffer (Node.js), typed array, blob, ...\n\n## Remarks\n\n- Most functions in loaders.gl that accept binary data call `toArrayBuffer(...)` on input parameters before starting processing, thus ensuring that functions work on all types of input data.\n","slug":"docs/api-reference/core/binary-utilities","title":"Binary Utilities"},{"excerpt":"encode Functions encode(fileData : ArrayBuffer | String, writer : Object | Array [, options : Object , url : String]) : Promise.Any Encodes…","rawMarkdownBody":"# encode\n\n## Functions\n\n### encode(fileData : ArrayBuffer | String, writer : Object | Array [, options : Object [, url : String]]) : Promise.Any\n\nEncodes data asynchronously using the provided writer.\n\n- `data` - loaded data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, options for the writer (see documentation of the specific writer).\n- `url` - optional, assists in the autoselection of a writer if multiple writers are supplied to `writer`.\n\n- `options.log`=`console` Any object with methods `log`, `info`, `warn` and `error`. By default set to `console`. Setting log to `null` will turn off logging.\n\n### encodeSync(fileData : ArrayBuffer | String, writer : Object | Array, [, options : Object [, url : String]]) : any\n\nEncodes data synchronously using the provided writer, if possible. If not, returns `null`, in which case asynchronous loading is required.\n\n- `data` - loaded data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, options for the writer (see documentation of the specific writer).\n- `url` - optional, assists in the autoselection of a writer if multiple writers are supplied to `writer`.\n","slug":"docs/api-reference/core/encode","title":"encode"},{"excerpt":"fetchFile The  function is a wrapper around  which provides support for path prefixes and some additional loading capabilities. Usage Use…","rawMarkdownBody":"# fetchFile\n\nThe `fetchFile` function is a wrapper around `fetch` which provides support for path prefixes and some additional loading capabilities.\n\n## Usage\n\nUse the `fetchFile` function as follows:\n\n```js\nimport {fetchFile} from '@loaders.gl/core';\n\nconst response = await fetchFile(url);\n\n// Now use standard browser Response APIs\n\n// Note: headers are case-insensitive\nconst contentLength = response.headers.get('content-length');\nconst mimeType = response.headers.get('content-type');\n\nconst arrayBuffer = await response.arrayBuffer();\n```\n\nThe `Response` object from `fetchFile` is usually passed to `parse` as follows:\n\n```js\nimport {fetchFile, parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nconst data = await parse(fetchFile(url), OBJLoader);\n```\n\nNote that if you don't need the extra features in `fetchFile`, you can just use the browsers built-in `fetch` method.\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nconst data = await parse(fetch(url), OBJLoader);\n```\n\n## Functions\n\n### fetchFile(url : String [, options : Object]) : Promise.Response\n\nA wrapper around the platform [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/fetch) function with some additions:\n\n- Supports `setPathPrefix`: If path prefix has been set, it will be appended if `url` is relative (e.g. does not start with a `/`).\n- Supports `File` and `Blob` objects on the browser (and returns \"mock\" fetch response objects).\n\nReturns:\n\n- A promise that resolves into a fetch [`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response) object, with the following methods/fields:\n    - `headers`: `Headers` - A [`Headers`](https://developer.mozilla.org/en-US/docs/Web/API/Headers) object.\n    - `arrayBuffer()`: Promise.ArrayBuffer` - Loads the file as an `ArrayBuffer`.\n    - `text()`: Promise.String` - Loads the file and decodes it into text.\n    - `json()`: Promise.String` - Loads the file and decodes it into JSON.\n    - `body` : ReadableStream` - A stream that can be used to incrementally read the contents of the file.\n\nOptions:\n\nUnder Node.js, options include (see [fs.createReadStream](https://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options)):\n\n- `options.highWaterMark` (Number) Default: 64K (64 \\* 1024) - Determines the \"chunk size\" of data read from the file.\n\n### readFileSync(url : String [, options : Object]) : ArrayBuffer | String\n\n> This function only works on Node.js or using data URLs.\n\nReads the raw data from a file asynchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n## Remarks\n\n- `fetchFile` will delegate to `fetch` after resolving the URL.\n- For some data sources such as node.js and `File`/`Blob` objects a mock `Response` object will be returned, and not all fields/members may be implemented.\n- When possible, `Content-Length` and `Content-Type` `headers` are also populated for non-request data sources including `File`, `Blob` and Node.js files.\n- `fetchFile` is intended to be a small (in terms of bundle size) function to help applications work with files in a portable way. The `Response` object returned on Node.js does not implement all the functionality the browser does. If you run into the need\n- In fact, the use of any of the file utilities including `readFile` and `readFileAsync` functions with other loaders.gl functions is entirely optional. loader objects can be used with data loaded via any mechanism the application prefers, e.g. directly using `fetch`, `XMLHttpRequest` etc.\n- The \"path prefix\" support is intentended to be a simple mechanism to support certain work-arounds. It is intended to help e.g. in situations like getting test cases to load data from the right place, but was never intended to support general application use cases.\n- The stream utilities are intended to be small optional helpers that facilitate writing platform independent code that works with streams. This can be valuable as JavaScript Stream APIs are still maturing and there are still significant differences between platforms. However, streams and iterators created directly using platform specific APIs can be used as parameters to loaders.gl functions whenever a stream is expected, allowing the application to take full control when desired.\n","slug":"docs/api-reference/core/fetch-file","title":"fetchFile"},{"excerpt":"load The  function can be used with any loader object. They takes a  and one or more loader objects, checks what type of data that loader…","rawMarkdownBody":"# load\n\nThe `load` function can be used with any _loader object_. They takes a `url` and one or more _loader objects_, checks what type of data that loader prefers to work on (e.g. text, JSON, binary, stream, ...), loads the data in the appropriate way, and passes it to the loader.\n\n### load(url : String | File, loaders : Object | Object[][, options : object]) : Promise.Response\n\n### load(url : String | File [, options : Object]) : Promise.Response\n\nThe `load` function is used to load and parse data with a specific _loader object_. An array of loader objects can be provided, in which case `load` will attempt to autodetect which loader is appropriate for the file.\n\nThe `loaders` parameter can also be omitted, in which case any _loader objects_ previously registered with [`registerLoaders`](docs/api-reference/core/register-loaders) will be used.\n\n- `url` - Urls can be data urls (`data://`) or a request (`http://` or `https://`) urls, or a file name (Node.js only). Also accepts `File` or `Blob` object (Browser only). Can also accept any format that is accepted by [`parse`](https://github.com/uber-web/loaders.gl/blob/master/docs/api-reference/core/parse.md), with the exception of strings that are interpreted as urls.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options` - optional, contains both options for the read process and options for the loader (see documentation of the specific loader).\n\n- `options.dataType`=`arraybuffer` - Default depends on loader object. Set to 'text' to read as text.\n\n`url` values\n\nReturns:\n\n- Return value depends on the _loader category_.\n\nNotes:\n\n- If `url` is not a `string`, `load` will call `parse` directly.\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n- `load` takes a `url` and a loader object, checks what type of data that loader prefers to work on (e.g. text, binary, stream, ...), loads the data in the appropriate way, and passes it to the loader.\n- If `@loaders.gl/polyfills` is installed, `load` will work under Node.js as well.\n\n","slug":"docs/api-reference/core/load","title":"load"},{"excerpt":"Iterator Utils Functions getStreamIterator(stream : Stream) : AsyncIterator Returns an async iterator that can be used to read chunks of…","rawMarkdownBody":"# Iterator Utils\n\n## Functions\n\n### getStreamIterator(stream : Stream) : AsyncIterator\n\nReturns an async iterator that can be used to read chunks of data from the stream (or write chunks of data to the stream, in case of writable streams).\n\nWorks on both Node.js 8+ and browser streams.\n","slug":"docs/api-reference/core/iterator-utilities","title":"Iterator Utils"},{"excerpt":"parse This function parses already loaded data. As a special case, it can also load (and then parse) data from a  or  response object…","rawMarkdownBody":"# parse\n\nThis function parses already loaded data. As a special case, it can also load (and then parse) data from a `fetch` or `fetchFile` response object).\n\n## Usage\n\nThe return value from `fetch` or `fetchFile` is a `Promise` that resolves to the fetch response object and can be passed directly to the non-sync parser functions:\n\n```js\nimport {fetchFile, parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\ndata = await parse(fetchFile(url), OBJLoader);\n// Application code here\n...\n```\n\nBatched (streaming) parsing is supported by some loaders\n\n```js\nimport {fetchFile, parseInBatches} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/obj';\n\nconst batchIterator = await parseInBatches(fetchFile(url), CSVLoader);\nfor await (const batch of batchIterator) {\n  console.log(batch.length);\n}\n```\n\n## Functions\n\n### parse(data : ArrayBuffer | String, loaders : Object | Object\\[] [, options : Object [, url : String]]) : Promise.Any\n\n### parse(data : ArrayBuffer | String, [, options : Object [, url : String]]) : Promise.Any\n\nParses data asynchronously either using the provided loader or loaders, or using the pre-registered loaders (see `register-loaders`).\n\n- `data`: loaded data or an object that allows data to be loaded. This parameter can be any of the following types:\n  - `Response` - `fetch` response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer` - Parse from binary data in an array buffer\n  - `String` - Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator` - Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n  - `AsyncIterator` - iterator that yeilds promises that resolve to binary (`ArrayBuffer`) chunks or string chunks.\n  - `ReadableStream` - A DOM or Node stream.\n  - `File` - A browser file object (from drag-and-drop or file selection operations).\n  - `Promise` - A promise that resolves to any of the other supported data types can also be supplied.\n\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of pre-registered loaders (see `registerLoaders`)\n\n- `options`: optional, options for the loader (see documentation of the specific loader).\n\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nOptions:\n\n- `options.log`=`console` Any object with methods `log`, `info`, `warn` and `error`. By default set to `console`. Setting log to `null` will turn off logging.\n\nReturns:\n\n- Return value depends on the _loader object_ category\n\nNotes:\n\n- If multiple `loaders` are provided (or pre-registered), an attempt will be made to autodetect which loader is appropriate for the file (using url extension and header matching).\n\n\n### parseSync(fileData : ArrayBuffer | String, loaders : Object | Object\\[], [, options : Object [, url : String]]) : any\n\n### parseSync(fileData : ArrayBuffer | String, [, options : Object [, url : String]]) : any\n\n> Synchronous parsing is not supported by all _loader objects_\n\nParses data synchronously using the provided loader, if possible. If not, returns `null`, in which case asynchronous parsing is required.\n\n- `data`: already loaded data, either in binary or text format. This parameter can be any of the following types:\n  - `Response`: `fetch` response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer`: Parse from binary data in an array buffer\n  - `String`: Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator`: Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n    can also be supplied.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options`: optional, options for the loader (see documentation of the specific loader).\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nReturns:\n\n- Return value depends on the _loader object_ category\n\n### parseInBatches(data : any, loaders : Object | Object\\[] [, options : Object [, url : String]]) : AsyncIterator\n\n### parseInBatches(data : any [, options : Object [, url : String]]) : AsyncIterator\n\n> Batched loading is not supported by all _loader objects_\n\nParses data in batches from a stream, releasing each batch to the application while the stream is still being read.\n\nParses data with the selected _loader object_. An array of `loaders` can be provided, in which case an attempt will be made to autodetect which loader is appropriate for the file (using url extension and header matching).\n\nThe `loaders` parameter can also be ommitted, in which case any _loader objects_ previously registered with [`registerLoaders`](docs/api-reference/core/register-loaders) will be used.\n\n- `data`: loaded data or an object that allows data to be loaded. This parameter can be any of the following types:\n  - `Response` - `fetch` response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer` - Parse from binary data in an array buffer\n  - `String` - Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator` - Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n  - `AsyncIterator` - iterator that yeilds promises that resolve to binary (`ArrayBuffer`) chunks or string chunks.\n  - `ReadableStream` - A DOM or Node stream.\n  - `Promise` - A promise that resolves to any of the other supported data types can also be supplied.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options`: optional, options for the loader (see documentation of the specific loader).\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nReturns:\n\n- Returns an async iterator that yields batches of data. The exact format for the batches depends on the _loader object_ category.\n","slug":"docs/api-reference/core/parse","title":"parse"},{"excerpt":"3D Tiles Category The 3D tile loaders are still under development. If you are interested in early access, please open an issue. Support for…","rawMarkdownBody":"# 3D Tiles Category\n\n> The 3D tile loaders are still under development. If you are interested in early access, please open an issue.\n\nSupport for loading and traversing [3D Tile Sets](https://github.com/AnalyticalGraphicsInc/3d-tiles).\n\nThe plan is to provide the following loaders/writers:\n- `Tile3DLoader` for individual tiles\n- `Tileset3DLoader` for the tileset\n- `Tile3DWriter` for individual tiles\n\nAnd the following helper classes\n- `Tileset3D` to help access the loaded tileset.\n- `Tile3D` to help access a loaded tile.\n- `Tileset3DTraversal` class that accepts view frustum parameters and returns a culled, prioritized list of tiles to show.\n- `Tileset3DCache` class that loads and LRU discards tiles based on prioritized lists (from Tileset3DTraversal).\n\nNote:\n- 3D tiles support in loaders.gl is developed in collaboration with the Cesium team.\n","slug":"docs/api-reference/3d-tile-loaders/category-3d-tiles","title":"3D Tiles Category"},{"excerpt":"save Needs update  and  function can be used with any writer.  takes a  and a writer object, checks what type of data that writer prefers to…","rawMarkdownBody":"# save\n\n> Needs update\n\n`save` and `saveSync` function can be used with any writer. `save` takes a `url` and a writer object, checks what type of data that writer prefers to work on (e.g. text, JSON, binary, stream, ...), saves the data in the appropriate way, and passes it to the writer.\n\n## Functions\n\n### save(url : String | File, writer : Object [, options : Object]) : Promise.ArrayBuffer| Promi\nse.String\n\nThe `save` function can be used with any writer.\n\n`save` takes a `url` and a writer object, checks what type of data that writer prefers to work on (e.g. text, JSON, binary, stream, ...), saves the data in the appropriate way, and passes it to the writer.\n\n- `url` - Can be a string, either a data url or a request url, or in Node.js, a file name, or in the browser, a File object.\n- `data` - saveed data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, contains both options for the read process and options for the writer (see documentation of the specific writer).\n- `options.dataType`=`arraybuffer` - By default reads as binary. Set to 'text' to read as text.\n\nReturns:\n\n- Return value depends on the category\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n### saveSync(url : String [, options : Object]) : ArrayBuffer | String\n\nSimilar to `save` except saves and parses data synchronously.\n\nNote that for `saveSync` to work, the `url` needs to be saveable synchronously _and_ the writer used must support synchronous parsing. Synchronous saveing only works on data URLs or files in Node.js. In many cases, the asynchronous `save` is more appropriate.\n","slug":"docs/api-reference/core/save","title":"save"},{"excerpt":"setPathPrefix resolvePath(path : String) : String Applies aliases and path prefix, in that order. Returns an updated path. addAliases…","rawMarkdownBody":"# setPathPrefix\n\n### resolvePath(path : String) : String\n\nApplies aliases and path prefix, in that order. Returns an updated path.\n\n### addAliases(aliases : Object)\n\nSets a map of aliases (file name substitutions).\n\n### setPathPrefix(prefix : String)\n\nThis sets a path prefix that is automatically prepended to relative path names provided to load functions.\n\n### getPathPrefix() : String\n\nReturns the current path prefix set by `setPathPrefix`.\n","slug":"docs/api-reference/core/set-path-prefix","title":"setPathPrefix"},{"excerpt":"registerLoaders The loader registry allows applications to cherry-pick which loaders to include in their application bundle by importing…","rawMarkdownBody":"# registerLoaders\n\nThe loader registry allows applications to cherry-pick which loaders to include in their application bundle by importing just the loaders they need and registering them during initialization.\n\nApplications can then make all those imported loaders available (via format autodetection) to all subsequent `parse` and `load` calls, without those calls having to specify which loaders to use.\n\n## Usage\n\nInitialization imports and registers loaders:\n\n```js\nimport {registerLoaders} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nregisterLoaders(CSVLoader);\n```\n\nSome other file that needs to load CSV:\n\n```js\nimport {load} from '@loaders.gl/core';\n\n// The pre-registered CSVLoader gets auto selected based on file extension...\nconst data = await load('data.csv');\n```\n\n## Functions\n\n### registerLoaders(loaders : Object | Object[])\n\nRegisters one or more _loader objects_ to a global _loader object registry_, these loaders will be used if no loader object is supplied to `parse` and `load`.\n\n- `loaders` - can be a single loader or an array of loaders. The specified loaders will be added to any previously registered loaders.\n","slug":"docs/api-reference/core/register-loaders","title":"registerLoaders"},{"excerpt":"writeFile A file save utilities that (attempts to) work consistently across browser and node. Usage Functions writeFile(url : String…","rawMarkdownBody":"# writeFile\n\nA file save utilities that (attempts to) work consistently across browser and node.\n\n## Usage\n\n```js\nimport {writeFile} from '@loaders.gl/core';\nimport {DracoWriter} from '@loaders.gl/draco';\n\nawait writeFile(url, DracoWriter);\n```\n\n## Functions\n\n### writeFile(url : String [, options : Object]) : Promise.ArrayBuffer\n\nReads the raw data from a file asynchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n### writeFileSync(url : String [, options : Object]) : ArrayBuffer\n\n> Only works on Node.js or using data URLs.\n\nReads the raw data from a \"file\" synchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n## Remarks\n\n- The use of the loaders.gl `writeFile` and `writeFileAsync` functions is optional, loaders.gl loaders can be used with any data loaded via any mechanism the application prefers, e.g. `fetch`, `XMLHttpRequest` etc.\n- The \"path prefix\" support is intentended to be a simple mechanism to support certain work-arounds. It is intended to help e.g. in situations like getting test cases to load data from the right place, but was never intended to support general application use cases.\n","slug":"docs/api-reference/core/write-file","title":"writeFile"},{"excerpt":"ZipLoader Decodes a Zip Archive into a file map. Loader Characteristic File Extension  File Format Binary Category Archive Data \"File Map…","rawMarkdownBody":"# ZipLoader\n\nDecodes a Zip Archive into a file map.\n\n| Loader         | Characteristic |\n| -------------- | -------------- |\n| File Extension | `.zip`         |\n| File Format    | Binary         |\n| Category       | Archive        |\n| Data           | \"File Map\"     |\n| Parser Type    | Asynchronous   |\n| Worker Thread  | No             |\n| Streaming      | No             |\n\n## Usage\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {ZipLoader} from '@loaders.gl/zip';\n\nconst fileMap = await parse(arrayBuffer, ZipLoader);\nfor (const fileName in FILE_MAP) {\n  const fileData = fileMap[key];\n  // Do something with the subfile\n}\n```\n\n## Input\n\n`ArrayBuffer` containing a valid Zip Archive\n\n## Output\n\nThe file map is an object with keys representing file names or relative paths in the zip file, and values being the contents of each sub file (either `ArrayBuffer` or `String`).\n\n## Options\n\nOptions are forwarded to [JSZip.loadAsync](https://stuk.github.io/jszip/documentation/api_jszip/load_async.html).\n\n## Attributions\n\nZipLoader is a wrapper around the [JSZip module](https://stuk.github.io/jszip/). JSZip has extensive documentation on options (and more functionality than this loader object can expose).\n","slug":"docs/api-reference/misc-loaders/zip-loader","title":"ZipLoader"},{"excerpt":"ZipWriter Encodes a filemap into a Zip Archive. Returns an  that is a valid Zip Archive and can be written to file. Loader Characteristic…","rawMarkdownBody":"# ZipWriter\n\nEncodes a filemap into a Zip Archive. Returns an `ArrayBuffer` that is a valid Zip Archive and can be written to file.\n\n| Loader         | Characteristic                                                  |\n| -------------- | --------------------------------------------------------------- |\n| File Extension | `.zip`                                                          |\n| File Type      | Binary                                                          |\n| File Format    | [Zip Format](<https://en.wikipedia.org/wiki/Zip_(file_format)>) |\n| Category       | Archive                                                         |\n| Data           | \"File Map\"                                                      |\n| Parser Type    | Asynchronous                                                    |\n| Worker Thread  | No                                                              |\n| Streaming      | No                                                              |\n\n## Usage\n\n```js\nimport {encode, writeFile} from '@loaders.gl/core';\nimport {ZipWriter} from '@loaders.gl/zip';\n\nconst FILEMAP = {\n  filename1: arrayBuffer1,\n  'directory/filename2': ...\n};\n\nconst arrayBuffer = await encode(FILE_MAP, ZipWriter)\nwriteFile(zipFileName, arrayBuffer);\n```\n\n## Input\n\nThe file map is an object with keys representing file names or relative paths in the zip file, and values being the contents of each sub file (either `ArrayBuffer` or `String`).\n\n## Options\n\nOptions are forwarded to [JSZip.generateAsync](https://stuk.github.io/jszip/documentation/api_jszip/generate_async.html), however type is always set to `arraybuffer` to ensure compatibility with writer driver functions in `@loaders.gl/core`.\n\n## Attributions\n\nZipWriter is a wrapper around the [JSZip module](https://stuk.github.io/jszip/). JSZip has extensive documentation on options (and more functionality than this writer object can expose).\n","slug":"docs/api-reference/misc-loaders/zip-writer","title":"ZipWriter"},{"excerpt":"Mesh (PointCloud) Loader Category Loaders such as , , ,  etc. all load a \"single geometry primitive\" consisting of a set of \"attributes…","rawMarkdownBody":"## Mesh (PointCloud) Loader Category\n\nLoaders such as `PCD`, `LAZ`, `PLY`, `OBJ` etc. all load a \"single geometry primitive\" consisting of a set of \"attributes\", perhaps `positions`, `colors`, `normals` etc. These attributes are all typed arrays containing successive values for each \"vertex\".\n\nThe mesh loaders do the following to standardize the loaded mesh\n\n- Provide a primitive drawing `mode` (the numeric values matches the corresponding WebGL constants).\n- Unpacks attributes (and indices if present) into typed arrays.\n- Wrap all attributes (and indices if present) into common \"accessor objects\": `{size: 1-4, value: typedArray}`.\n- Maps known attribute names to glTF attribute names.\n- Add `indices` field to the result (only if indices are present in the loaded geometry).\n\n### PointCloud/Mesh Data Structure\n\n| Field        | Type                | Contents                                                                                                                 |\n| ------------ | ------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n| `loaderData` | `Object` (Optional) | Loader and format specific data                                                                                          |\n| `header`     | `Object`            | See below                                                                                                                |\n| `mode`       | `Number`            | Aligned with [OpenGL/glTF primitive types](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#primitive) |\n| `attributes` | `Object`            | Each key contains an \"accessor\" object representing the contents of one attribute.                                       |\n| `indices`    | `Object` (Optional) | If present, contains the indices (elements) typed array (`Uint32Array` or `Uint16Array`).                                |\n\nNote that glTF attributes (keys in the `glTFAttributeMap`) are named per [glTF 2.0 recommendations](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#geometry) with standardized, captilalized names.\n\n### Header Object\n\nThe `header` fields are only recommended at this point, applications can not assume they will be present:\n\n| `header` Field | Type     | Contents |\n| -------------- | -------- | -------- |\n| `vertexCount`  | `Number` |          |\n\n### Primitive Mode\n\nPrimitive modes are the usual standard WebGL/OpenGL constants:\n\n| Value | Primitive Mode   | Comment                                                                                              |\n| ----- | ---------------- | ---------------------------------------------------------------------------------------------------- |\n| `0`   | `POINTS`         | Used for point cloud category data                                                                   |\n| `1`   | `LINES`          | Lines are rarely used due to limitations in GPU-based rendering                                      |\n| `2`   | `LINE_LOOP`      | -                                                                                                    |\n| `3`   | `LINE_STRIP`     | -                                                                                                    |\n| `4`   | `TRIANGLES`      | Used for most meshes. Indices attributes are often used to reuse vertex data in remaining attributes |\n| `5`   | `TRIANGLE_STRIP` | -                                                                                                    |\n| `6`   | `TRIANGLE_FAN`   | -                                                                                                    |\n\n### Accessors\n\n`attributes` and `indices` are represented by glTF \"accessor objects\" with the binary data for that attribute resolved into a typed array of the proper type.\n\n| Accessors Fields | glTF? | Type                | Contents                                                                                                                                           |\n| ---------------- | ----- | ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `value`          | No    | `TypedArray`        | Contains the typed array (corresponds to `bufferView`). The type of the array will match the GL constant in `componentType`.                       |\n| `size`           | No    | `1`-`4`             | Decoded \"type\". i.e. number of components                                                                                                          |\n| `byteOffset`     | Yes   | `Number`            | Starting offset into the bufferView. Currently always `0`                                                                                          |\n| `count`          | Yes   | `Number`            | The number of elements/vertices in the attribute data                                                                                              |\n| `originalName`   | No    | `String` (Optional) | If this was a named attribute in the original file, the original name (before substitution with glTF attribute names) will be made available here. |\n\n### GLTF Attribute Name Mapping\n\nAlso, to help applications manage attribute name differences between various formats, mesh loaders map known attribute names to [glTF 2.0 standard attribute names](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#geometry) a best-effort basis.\n\nWhen a loader can map an attribute name, it will replace ir with the glTF equivalent. This allows applications to use common code to handle meshes and point clouds from different formats.\n\n| Name         | Accessor Type(s)     | Component Type(s)                                                                                                  | Description                                                                                                        |\n| ------------ | -------------------- | ------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------ |\n| `POSITION`   | `\"VEC3\"`             | `5126` (FLOAT)                                                                                                | XYZ vertex positions                                                                                               |\n| `NORMAL`     | `\"VEC3\"`             | `5126` (FLOAT)                                                                                                | Normalized XYZ vertex normals                                                                                      |\n| `TANGENT`    | `\"VEC4\"`             | `5126` (FLOAT)                                                                                                | XYZW vertex tangents where the _w_ component is a sign value (-1 or +1) indicating handedness of the tangent basis |\n| `TEXCOORD_0` | `\"VEC2\"`             | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | UV texture coordinates for the first set                                                                           |\n| `TEXCOORD_1` | `\"VEC2\"`             | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | UV texture coordinates for the second set                                                                          |\n| `COLOR_0`    | `\"VEC3\"`, `\"VEC4\"` | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | RGB or RGBA vertex color                                                                                           |\n| `JOINTS_0`   | `\"VEC4\"`             | `5121` (UNSIGNED_BYTE), `5123` (UNSIGNED_SHORT)                                                        | See [Skinned Mesh Attributes](#skinned-mesh-attributes)                                                            |\n| `WEIGHTS_0`  | `\"VEC4\"`             | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | See [Skinned Mesh Attributes](#skinned-mesh-attributes)                                                            |\n\n> Note that for efficiency reasons, mesh loaders are not required to convert the format of an attribute's binary data to match the glTF specifications (i.e. if normals were encoded using BYTES then that is what will be returned even though glTF calls out for FLOAT32). Any such alignment needs to be done by the application as a second step.\n\n## Scenegraph Format Support\n\nFor more complex, scenegraph-type formats (i.e. formats that don't just contain single geometric primitives), loaders.gl currently focuses on glTF 2.0 support.\n\nIt is assumed that other scenegraph-type format loaders (e.g. a hyptothetical COLLADA loader) could convert their loaded data to a similar structure, essentially converting to glTF 2.0 on-the-fly as they load.\n\nFor now it is best to convert such assets off-line to glTF before attempting to loade them with loaders.gl.\n\n### Material support\n\nMaterial support is provided by some mesh formats (e.g. OBJ/MTL) and is currently not implemented by loaders.gl, however the glTF loader has full support for PBR (Physically-Based Rendering) materials.\n","slug":"docs/api-reference/mesh-loaders/category-mesh","title":" Mesh (PointCloud) Loader Category"},{"excerpt":"DracoLoader Decodes a mesh or point cloud (maps of attributes) using DRACO compression compression. Loader Characteristic File Extension…","rawMarkdownBody":"# DracoLoader\n\nDecodes a mesh or point cloud (maps of attributes) using [DRACO compression](https://google.github.io/draco/) compression.\n\n| Loader                | Characteristic                                                        |\n| --------------------- | --------------------------------------------------------------------- |\n| File Extension        | `.drc`                                                                |\n| File Type             | Binary                                                                |\n| File Format           | [Draco](https://google.github.io/draco/)                              |\n| Parser Category       | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md) |\n| Parser Type           | Synchronous                                                           |\n| Worker Thread Support | Yes                                                                   |\n| Streaming Support     | No                                                                    |\n\n## Usage\n\n```js\nimport {DracoLoader} from '@loaders.gl/draco';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, DracoLoader, options);\n```\n\n## Options\n\nN/A\n\n## Data Format\n\n`DracoLoader` loads a single primitive geometry for a point cloud or mesh and the return data follows the conventions for those categories.\n\n## Attribution/Credits\n\nBased on Draco examples\n","slug":"docs/api-reference/mesh-loaders/draco-loader","title":"DracoLoader"},{"excerpt":"DracoWriter Encodes a mesh or point cloud (maps of attributes) using Draco3D compression. Loader Characteristic File Extension  File Typoe…","rawMarkdownBody":"# DracoWriter\n\nEncodes a mesh or point cloud (maps of attributes) using [Draco3D](https://google.github.io/draco/) compression.\n\n| Loader                | Characteristic                                                        |\n| --------------------- | --------------------------------------------------------------------- |\n| File Extension        | `.drc`                                                                |\n| File Typoe            | Binary                                                                |\n| File Format           | [Draco](https://google.github.io/draco/)                              |\n| Data Format           | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md) |\n| Encoder Type          | Synchronous                                                           |\n| Worker Thread Support | Yes                                                                   |\n| Streaming Support     | No                                                                    |\n\n## Usage\n\n```js\nimport {DracoWriter} from '@loaders.gl/draco';\nimport {encode} from '@loaders.gl/core';\n\nconst mesh = {\n  attributes: {\n    POSITION: {...}\n  }\n};\n\nconst data = await encode(mesh, DracoWriter, options);\n```\n\n## Options\n\n- `pointcloud`=`false` (Boolean): Set to `true` to compress pointclouds (mode=`0` and no `indices`)/\n- `method`=`MESH_EDGEBREAKER_ENCODING` (String) - set Draco encoding method (applies to meshes only)\n- `speed`=`[5, 5]` ([Number, Number] - set Draco speed options.\n- `quantization`=`{POSITION: 10}` (Object) - set Draco attribute quantization. Lower numbers means higher compression but more information loss.\n- `log`= (Function) - callback for debug info.\n\n## Input Data\n\nAccepts a standardized mesh.\n\n## Attribution/Credits\n\nBased on Draco examples\n","slug":"docs/api-reference/mesh-loaders/draco-writer","title":"DracoWriter"},{"excerpt":"LASLoader The LASER (LAS) file format is a public format for the interchange of 3-dimensional point cloud data data, developed for LIDAR…","rawMarkdownBody":"# LASLoader\n\nThe LASER (LAS) file format is a public format for the interchange of 3-dimensional point cloud data data, developed for LIDAR mapping purposes.\n\n| Loader                | Characteristic                                                                                                           |\n| --------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n| File Extension        | `.las`                                                                                                                   | `.laz` |\n| File Type             | Binary                                                                                                                   |\n| File Format           | [LASER FILE FORMAT](https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities) |\n| Data Format           | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md)                                                    |\n| Encoder Type          | Synchronous                                                                                                              |\n| Worker Thread Support | Yes                                                                                                                      |\n| Streaming Support     | No                                                                                                                       |\n\nNote: LAZ is the compressed version of LAS\n\n## Usage\n\n```js\nimport {LASLoader} from '@loaders.gl/las';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, LASLoader, options);\n```\n\n## Options\n\n- `skip`=`1` (Number) - Read one from every _n_ points. Default `1`.\n- `onProgress`= (Number) - Callback when a new chunk of data is read.\n\n## Attribution/Credits\n\nLASLoader is a fork of Uday Verma and Howard Butler's [plasio](https://github.com/verma/plasio/) under MIT License.\n","slug":"docs/api-reference/mesh-loaders/las-loader","title":"LASLoader"},{"excerpt":"OBJLoader This loader handles the OBJ half of the classic Wavefront OBJ/MTL format. The OBJ format is a simple ASCII format that lists…","rawMarkdownBody":"# OBJLoader\n\nThis loader handles the OBJ half of the classic Wavefront OBJ/MTL format. The OBJ format is a simple ASCII format that lists vertices, normals and faces on successive lines.\n\n| Loader                | Characteristic                                                          |\n| --------------------- | ----------------------------------------------------------------------- |\n| File Extension        | `.obj`                                                                  |\n| File Type             | Text                                                                    |\n| File Format           | [Wavefront OBJ file](https://en.wikipedia.org/wiki/Wavefront_.obj_file) |\n| Data Format           | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md)   |\n| Encoder Type          | Synchronous                                                             |\n| Worker Thread Support | Yes                                                                     |\n| Streaming Support     | No                                                                      |\n\n## Usage\n\n```js\nimport {OBJLoader} from '@loaders.gl/obj';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, OBJLoader);\n```\n\n## Loader Options\n\nN/A\n\n## Data Loaded\n\n- `positions` -\n- `normals` -\n- `faces` -\n\n## Attribution/Credits\n\nOBJLoader is a wrapper around the [`webgl-obj-loader`](https://www.npmjs.com/package/webgl-obj-loader) module.\n","slug":"docs/api-reference/mesh-loaders/obj-loader","title":"OBJLoader"},{"excerpt":"PCDLoader A point cloud format defined by the Point Cloud Library. Loader Characteristic File Extension  File Type Text/Binary File Format…","rawMarkdownBody":"# PCDLoader\n\nA point cloud format defined by the [Point Cloud Library](https://en.wikipedia.org/wiki/Point_Cloud_Library).\n\n| Loader                | Characteristic                                                                            |\n| --------------------- | ----------------------------------------------------------------------------------------- |\n| File Extension        | `.pcd`                                                                                    |\n| File Type             | Text/Binary                                                                               |\n| File Format           | [Point Cloud Library](http://pointclouds.org/documentation/tutorials/pcd_file_format.php) |\n| Data Format           | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md)                     |\n| Encoder Type          | Synchronous                                                                               |\n| Worker Thread Support | Yes                                                                                       |\n| Streaming Support     | No                                                                                        |\n\nNote: Currently only `ascii` and `binary` subformats are supported. Compressed binary files are currently not supported.\n\n## Usage\n\n```js\nimport {PCDLoader} from '@loaders.gl/pcd';\nimport {load} from '@loaders.gl/core';\n\nconst {header, attributes} = await load(url, PCDLoader);\n// Application code here, e.g:\n// return new Geometry(attributes)\n```\n\nLoads `position`, `normal`, `color` attributes.\n\n## Attribution/Credits\n\nPCDLoader loader is a fork of the THREE.js PCDLoader under MIT License. The THREE.js source files contained the following attributions:\n\n- @author Filipe Caixeta / http://filipecaixeta.com.br\n- @author Mugen87 / https://github.com/Mugen87\n","slug":"docs/api-reference/mesh-loaders/pcd-loader","title":"PCDLoader"},{"excerpt":"PLYLoader PLY is a computer file format known as the Polygon File Format or the Stanford Triangle Format. It was principally designed to…","rawMarkdownBody":"# PLYLoader\n\nPLY is a computer file format known as the Polygon File Format or the Stanford Triangle Format. It was principally designed to store three-dimensional data from 3D scanners.\n\n| Loader                | Characteristic                                                        |\n| --------------------- | --------------------------------------------------------------------- |\n| File Extension        | `.ply`                                                                |\n| File Type             | Binary/Text                                                           |\n| File Format           | [PLY format](<https://en.wikipedia.org/wiki/PLY_(file_format)>)       |\n| Data Format           | [Standardized Mesh](docs/api-reference/mesh-loaders/category-mesh.md) |\n| Encoder Type          | Synchronous                                                           |\n| Worker Thread Support | Yes                                                                   |\n| Streaming Support     | No                                                                    |\n\n## Usage\n\n```js\nimport {PLYLoader} from '@loaders.gl/ply';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, PLYLoader);\n```\n\n## Attribution/Credits\n\nPLYLoader is a fork of the THREE.js PLYLoader under MIT License. The THREE.js source files contained the following attributions:\n\n@author Wei Meng / http://about.me/menway\n","slug":"docs/api-reference/mesh-loaders/ply-loader","title":"PLYLoader"},{"excerpt":"Polyfills Older browsers (mainly Edge and IE11) as well as versions of Node.js prior to v11 do not provide certain classes that loaders.gl…","rawMarkdownBody":"# Polyfills\n\nOlder browsers (mainly Edge and IE11) as well as versions of Node.js prior to v11 do not provide certain classes that loaders.gl depends on.\n\nWhile there are many good polyfill modules available on `npm`, to make the search for a version that works perfectly with loaders.gl a little easier, a polyfill module is included.\n\n## Usage\n\nJust import `@loaders.gl/polyfills` before you start using other loaders.gl modules.\n\n```js\nimport '@loaders.gl/polyfills';\nimport '@loaders.gl/core';\n```\n\n## Included Polyfills\n\n| Polyfill  | Node   | Browser  | Comments |\n| ---       | ---       | ---      |\n| `TextEncoder`/`TextDecoder` | Node.js < 11 | Yes (Older browsers) | Only UTF8 is guaranteed to be supported |\n| `atob`/`btoa` | All versions | No | Note: these functions are [not unicode safe](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/Base64_encoding_and_decoding#The_Unicode_Problem), but OK to use for test cases. |\n| `fetch` | All versions | No | A subset of the fetch API is supported, see below. |\n\n## fetch Polyfill\n\nThe Node.js `fetch` polyfill supports a subset of the browser fetch API, including:\n- `Response.text()`, `Response.arrayBuffer()`.\n- `Response.body` stream\n- limited support for `headers`\n- data uri / base64 decoding\n\n\n# TextEncoder and TextDecoder Polyfills\n\n`TextEncoder` and `TextDecoder` polyfills are provided to ensure these APIs are always available. In modern browsers these will evaluate to the built-in objects of the same name, however under Node.js polyfills are transparently installed.\n\nNote: The provided polyfills only guarantee UTF8 support.\n\n## Remarks\n\n- Applications should only install this module if they need to run under older environments. While the polyfills are only installed at runtime if the platform does not already support them, importing this module will increase the application's bundle size.\n- Refer to browser documentation for the usage of these classes, e.g. MDN.\n- In the browser, overhead of using these imports is very low, as most polyfills are only bundled under Node.js.\n- If working under older browsers, e.g. IE11, you may need to install your own TextEncoder/TextDecoder polyfills before loading this library\n\n## Attribution\n\nThe `Header` polyfill (for Node.js `fetch`) is a fork of the implementation in https://github.com/github/fetch (MIT license).\n","slug":"docs/api-reference/polyfills","title":"Polyfills"},{"excerpt":"GLTF Loader Category Data Format A gltf scenegraph is described by a parsed JSON object (with top level arrays for ,  etc) together with a…","rawMarkdownBody":"# GLTF Loader Category\n\n## Data Format\n\nA gltf scenegraph is described by a parsed JSON object (with top level arrays for `scenes`, `nodes` etc) together with a list of `ArrayBuffer`s representing binary blocks into which `bufferViews` and `images` in the JSON point).\n\nAt their core glTF and GLB loaders extract this information, however additional classes are provided to make processing of the returned data easier.\n\nWhile the glTF \"category\" is obviously quite specific glTF, loaders for other scenegraph formats (e.g. COLLADA) could potentially also choose to \"convert\" the loaded data to this glTF format and thus enable interoperabiity with applications that are already designed to use the `GLTFLoader`.\n\n### GLB Data Format\n\nAn object with the following top-level fields:\n\n| Field     | Type          | Default   | Description |\n| ---       | ---           | ---       | --- |\n| `magic`   | `Number`      | glTF      | The first four bytes of the file |\n| `version` | `Number`      | `2`       | The version number |\n| `json`    | `Object`      | `{}`      | The JSON chunk  |\n| `binary`  | `ArrayBuffer` | `null`    | The binary chunk, or `null` |\n\n\n### GLTF Data Format\n\nIn loaders.gl, glTF data is a pure JavaScript object with the following fields:\n\n| Field     | Type            | Default   | Description |\n| ---       | ---             | ---       | --- |\n| `magic`   | `Number`        | glTF      | The first four bytes of the file |\n| `version` | `Number`        | `2`       | The version number |\n| `json`    | `Object`        | `{}`      | The JSON chunk (glTF formatted)  |\n| `buffers` | `ArrayBuffer[]` | `[]`      | The BIN chunk plus any base64 or BIN file buffers |\n\nBuffers can be objects with `{buffer, byteOffset, byteLength}`.\n\n\n## GLTFScenegraph API\n\nTo simplify traversing and building glTF data objects, the [`GLTFScenegraph`](docs/api-reference/gltf/gltf-scenegraph) class can be used.\n\nA gltf\n\n\nA glTF data object can also be built programmatically using the GLTFScenegraph's \"fluent API\":\n\n```js\nimport {encode} from '@loaders.gl/gltf';\nimport {GLTFScenegraph, GLTFWriter} from '@loaders.gl/gltf';\nconst gltfScenegraph = new GLTFScenegraph()\n  .addApplicationData(...)\n  .addExtras(...)\n  .addExtension(...)\n  .addRequiredExtension(...);\n\nconst arrayBuffer = encode(gltfScenegraph, GLTFWriter);\n```\n\n## GLTF Post Processing\n\nThe [`postProcessGLTF`](docs/api-reference/gltf/post-process-gltf) function implements a number of transformations on the loaded glTF data that would typically need to be performed by the application after loading the data, and is provided as an optional function that applications can call after loading glTF data. Refer to the reference page for details on what transformations are performed.\n\nContext: the glTF data object returned by the GLTF loader contains the \"raw\" glTF JSON structure (to ensure generality and \"data fidelity\" reasons). However, most applications that are going to use the glTF data to visualize it in (typically in WebGL) will need to do some processing of the loaded data before using it.\n\n## Using GLB as a \"Binary Container\" for Arbitrary Data\n\nThe GLB binary container format used by glTF addresses a general need to store a mix of JSON and binary data, and can potentially be used as a foundation for building custom loaders and writers.\n\nTo allow for this (and also to generally improve the glTF code structure), the `GLTFLoader` and `GLTFBuilder` classes are built on top of GLB focused classes (`GLBLoader` and `GLBBuilder`) that can be used independently of the bigger glTF classes.\n\n## glTF Extension Support\n\nCertain glTF extensions are fully or partially supported by the glTF classes. For details on which extensions are supported, see [glTF Extensions](docs/api-reference/gltf-loaders/gltf-extensions).\n\n## Draco Mesh and Point Cloud Compression\n\nDraco encoding and decoding is supported by the `GLTFBuilder` and `GLTFParser` classes but requires the DracoWriter and DracoLoader dependencies to be \"injected\" by the application.\n\n```js\nimport {GLTFBuilder} from '@loaders.gl/gltf';\nimport {DracoWriter, DracoLoader} from '@loaders.gl/draco';\n\nconst gltfBuilder = new GLTFBuilder({DracoWriter, DracoLoader});\n```\n\n","slug":"docs/api-reference/gltf-loaders/category-gltf","title":"GLTF Loader Category"},{"excerpt":"GLBLoader The  is a writer for GLB binary \"envelope\". Note: applications that want to parse GLB-formatted glTF files use the  instead. The…","rawMarkdownBody":"# GLBLoader\n\nThe `GLBLoader` is a writer for GLB binary \"envelope\".\n\nNote: applications that want to parse GLB-formatted glTF files use the `GLTFLoader` instead. The `GLBLoader` is intended to be used to load custom data that combines JSON and binary resources.\n\n| Loader                | Characteristic                                                                                          |\n| --------------------- | ------------------------------------------------------------------------------------------------------- |\n| File Extensions       | `.glb`                                                                                                  |\n| File Types            | Binary                                                                                                  |\n| File Format           | [GLB](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#glb-file-format-specification) |\n| Format Category       | N/A (GLB Payload)                                                                                       |\n| Writer Type           | Synchronous                                                                                             |\n| Worker Thread Support | No                                                                                                      |\n| Streaming Support     | No                                                                                                      |\n\n## Usage\n\n```\nimport {load} from '@loaders.gl/core';\nimport {GLBLoader} from '@loaders.gl/gltf';\nconst gltf = await load(url, GLBLoader);\n```\n\n## Data Format\n\n```js\n{\n  type: String,\n  magic: Number,\n  version: Number,\n  json: Object,\n  binary: ArrayBuffer\n}\n```\n\n## Options\n\n| Option  | Default   | Description                              |\n| ------- | -------   | ---------------------------------------- |\n| `magic` | `glTF`    | The magic number to be save in the file. |\n\n## Attributions\n\nThe `GLBLoader` was developed for loaders.gl.\n","slug":"docs/api-reference/gltf-loaders/glb-loader","title":"GLBLoader"},{"excerpt":"GLBWriter The  is a writer for the GLB binary \"envelope\". Note: applications that want to encode GLB-formatted glTF files use the  instead…","rawMarkdownBody":"# GLBWriter\n\nThe `GLBWriter` is a writer for the GLB binary \"envelope\".\n\nNote: applications that want to encode GLB-formatted glTF files use the `GLTFWriter` instead. The `GLBWriter` is intended to be used to save custom data that combines JSON and binary resources.\n\n| Writer                | Characteristic                                                                                          |\n| --------------------- | ------------------------------------------------------------------------------------------------------- |\n| File Extensions       | `.glb`                                                                                                  |\n| File Type             | Binary                                                                                                  |\n| File Format           | [GLB](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#glb-file-format-specification) |\n| Format Category       | N/A (GLB Payload)                                                                                       |\n| Writer Type           | Synchronous                                                                                             |\n| Worker Thread Support | No                                                                                                      |\n| Streaming Support     | No                                                                                                      |\n\n## Usage\n\n```js\nimport {GLBWriter} from '@loaders.gl/gltf';\nimport {encodeSync} from '@loaders.gl/core';\n\nconst arrayBuffer = encodeSync(gltf, GLBWriter, options);\n```\n\n## Data Format\n\nReturns an object with the following fields:\n\n| Field     | Type          | Default   | Description |\n| ---       | ---           | ---       | --- |\n| `magic`   | `Number`      | glTF      | The first four bytes of the file |\n| `version` | `Number`      | `2`       | The version number |\n| `json`    | `Object`      | `{}`      | The JSON chunk  |\n| `binary`  | `ArrayBuffer` | `null`    | The binary chunk, or `null` |\n\n\n## Attributions\n\nThe `GLBWriter` was developed for loaders.gl.\n","slug":"docs/api-reference/gltf-loaders/glb-writer","title":"GLBWriter"},{"excerpt":"glbdump  is a utility for inspecting the structure of GLB/glTF binary container files. Installing loaders.gl/gltf makes the  command line…","rawMarkdownBody":"## glbdump\n\n`glbdump` is a utility for inspecting the structure of GLB/glTF binary container files.\n\nInstalling loaders.gl/gltf makes the `glbdump` command line tool available. It can be run using `npx`.\n\n```\n$ npx glbdump <filename>\n```\n","slug":"docs/api-reference/gltf-loaders/glbdump","title":" glbdump"},{"excerpt":"glTF Extensions Arbitrary glTF extensions can be present in glTF files, and will remain present in the parsed JSON as you would expect. Such…","rawMarkdownBody":"# glTF Extensions\n\nArbitrary glTF extensions can be present in glTF files, and will remain present in the parsed JSON as you would expect. Such extensions can supported by applications by inspecting the `extensions` fields inside glTF objects, and it is up to each application to handle or ignore them.\n\nMany glTF extensions affect e.g. rendering which is outside of the scope of loaders.gl, however in a few cases it is possible to provide support for extensions directly during loading. This article describes glTF extensions that are fully or partially processed by the `@loaders.gl/gltf` classes.\n\n## Official Extensions\n\n### KHR_draco_mesh_compression\n\nSupports compression of mesh attributes (geometry).\n\nSpecification: [KHR_draco_mesh_compression](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression).\n\nParsing Support:\n\n- By adding the `decompress: true` options to the `GLTFParser` any decompressed by the `GLTFParser`.\n- The expanded attributes are placed in the mesh object (effectively making it look as if it had never been compressed).\n- The extension objects are removed from the glTF file.\n\nEncoding Support:\n\n- Meshes can be compressed as they are added to the `GLTFBuilder`.\n\n### KHR_lights_punctual\n\nSupports specification of point light sources and addition of such sources to the scenegraph node.\n\nSpecification: [KHR_lights_punctual](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual)\n\nParsing Support:\n\n- Any nodes with a `KHR_lights_punctual` extension will get a `light` field with value containing a light definition object with properties defining the light (this object will be resolved by index from the global `KHR_lights_punctual` extension object's `lights` array) .\n- The `KHR_lights_punctual` extensions will be removed from all nodes.\n- Finally, the global `KHR_lights_punctual` extension (including its light list)) will be removed.\n\nEncoding Support:\n\n- N/A\n\n## Custom Extensions\n\n### UBER_draco_point_cloud_compression\n\nSpecification: Similar to `KHR_draco_mesh_compression`, but supports point clouds (draw mode 0). Also does not support any fallback or non-compressed accessors/attributes.\n\nParsing support:\n\n- The primitive's accessors field will be populated after decompression.\n- After decompression, the extension will be removed (as if the point cloud was never compressed).\n\nEncoding support:\n\n- Point clouds can be compressed as they are added to the `GLTFBuilder` and decompressed by the `GLTFParser`.\n","slug":"docs/api-reference/gltf-loaders/gltf-extensions","title":"glTF Extensions"},{"excerpt":"GLTFLoaders Parses a glTF file into a hierarchical scenegraph description that can be used to instantiate an actual Scenegraph in most WebGL…","rawMarkdownBody":"# GLTFLoaders\n\nParses a glTF file into a hierarchical scenegraph description that can be used to instantiate an actual Scenegraph in most WebGL libraries. Can load both binary `.glb` files and JSON `.gltf` files.\n\nAlso, certain glTF extensions can be fully or partially processed during loading. See [glTF Extensions](docs/api-reference/gltf-loaders/gltf-extensions.md).\n\n| Loader                | Characteristic                                                             |\n| --------------------- | -------------------------------------------------------------------------- |\n| File Extensions       | `.glb`,`.gltf`                                                             |\n| File Types            | Binary/JSON/Linked Assets                                                  |\n| File Format           | [glTF](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0) |\n| Format Category       | [glTF Scenegraph Category](docs/api-reference/gltf-loaders/category-gltf.md)                                                             |\n| Parser Type           | Asynchronous (Synchronous w/ limited functionality)                        |\n| Worker Thread Support | No                                                                         |\n| Streaming Support     | No                                                                         |\n\n\n## Usage\n\n```\nimport {load} from '@loaders.gl/core';\nimport {GLTFLoader} from '@loaders.gl/gltf';\nconst gltf = await load(url, GLTFLoader);\n```\n\nTo decompress Draco-compressed meshes:\n\n```\nimport {load} from '@loaders.gl/core';\nimport {GLTFLoader} from '@loaders.gl/gltf';\nimport {DracoLoader} from '@loaders.gl/draco';\nconst gltf = load(url, GLTFLoader, {DracoLoader, decompress: true});\n```\n\n## Options\n\n| Option                 | Default     | Description                                                                                      |\n| ---------------------- | ----------- | ------------------------------------------------------------------------------------------------ |\n| `fetchLinkedResources` | `true`      | Fetch any linked .BIN files, decode base64 encoded URIS. Only supported in asynchronous parsing. |\n| `fetch`                | `fetchFile` | Function used to fetch linked resources                                                          |\n| `decompress`           | `true`      | Decompress Draco compressed meshes (if DracoLoader available)                                    |\n| `DracoLoader`          | `null`      | Supply to enable decoding of Draco compressed meshes.                                            |\n| `postProcess`          | `false`     | Perform additional post processing to simplify use in WebGL libraries                            |\n| `createImages`         | `false`     | Create image objects from loaded image data                                                      |\n\n## Structure of Loaded Data\n\nSee [glTF Scenegraph Category](docs/api-reference/gltf-loaders/category-gltf.md).\n\nWhen parsed asynchronously (e.g. not using `parseSync`):\n\n- linked binary resources will be loaded and resolved (if url is available).\n- base64 encoded binary data inside the JSON payload will be decoded\n\n## Attributions\n\nThe `GLTFLoader` was developed for loaders.gl.\n","slug":"docs/api-reference/gltf-loaders/gltf-loader","title":"GLTFLoaders"},{"excerpt":"postProcessGLTF The  function transforms parsed GLTF JSON to make it easier to use. Usage To post process just pass a gltf object to the…","rawMarkdownBody":"# postProcessGLTF\n\nThe `postProcessGLTF` function transforms parsed GLTF JSON to make it easier to use.\n\n## Usage\n\nTo post process just pass a gltf object to the `GLTFPostProcessor`\n```js\nimport {GLTFLoader, postProcessGLTF} from '@loaders.gl/gltf';\nconst gltf = await parse(..., GLTFLoader);\nconst processedGLTF = postProcesssGLTF(gltf);\n````\n\nAfter post-processing, the gltf scenegraphs are now easier to iterate over\n```js\nconst scenegraph = processedGLTF.scenegraphs[0];\nfor (const node of scenegraph.nodes) { // no need to resolve indices\n  if (node.mesh.primitives) { // Ditto\n  \t// ...\n  }\n}\n```\n\n## Functions\n\n### postProcessGLTF(gltf, options = {})\n\n- `gltf` is expected to have `json` and `buffers` fields per the GLTF Data Format Category.\n- `options.uri` - Set base URI (for image loading)\n\nThe GLTF post processor copies objects in the input gltf json field as necessary to avoid modifying the input JSON, but does not do a deep copy on sub-objects that do not need to be modified.\n\n\n## General Post Processing\n\n### Replace indices with references\n\nThe GLTF file format links nodes through indices. The `nodes` field in an object in the top-level glTF `scenegraph` array. is an array of indices into the top-level `nodes` array. Each node has a `mesh` attribute that is an index into to the `meshes` array, and so on.\n\nHaving to follow indices is inconvenient when working with the gltf data in JavaScript. So during post processing, indices will be replaced with references to the indexed objects, enabling applications to use simple iteration to follow the scenegraph.\n\n\n### Adds `id` to every node\n\nUnless already present.\n\n## Node Specific Post Processing\n\n### BufferViews\n\n* Typed arrays (`Uint8Arrays`) will be created for buffer views and added to `bufferView.data` field. These typed arrays can be used to upload data to WebGL buffers.\n\n### Accessors\n\nThe accessor parameters which are textual strings in glTF will be resolved into WebGL constants.\n\n### Texture\n\nModifies\n- `sampler` - will be resolved the the corresponding image object.\n- `source` - will be resolved the the corresponding image object.\n\n### Samplers\n\nModifies\n- `parameters` - see table\n\nSampler parameters (which are textual in glTF) will be resolved into WebGL constants.\n\n| glTF constant | WebGL constant |\n| --- | --- |\n| `magFilter` | `GL.TEXTURE_MAG_FILTER` |\n| `minFilter` | `GL.TEXTURE_MIN_FILTER` |\n| `wrapS` | `GL.TEXTURE_WRAP_S` |\n| `wrapT` | `GL.TEXTURE_WRAP_T` |\n\n\n### Materials\n\nAdds:\n- Since each texture object in the material has an `index` field next to other fields, the post processor will add a `texture` field instead of replacing the `index` field.\n","slug":"docs/api-reference/gltf-loaders/post-process-gltf","title":"postProcessGLTF"},{"excerpt":"GLTFWriter The  is a writer for glTF scenegraphs. Writer Characteristic File Extensions , File Types Binary/JSON/Linked Assets File Format…","rawMarkdownBody":"# GLTFWriter\n\nThe `GLTFWriter` is a writer for glTF scenegraphs.\n\n| Writer                | Characteristic                                                             |\n| --------------------- | -------------------------------------------------------------------------- |\n| File Extensions       | `.glb`,`.gltf`                                                             |\n| File Types            | Binary/JSON/Linked Assets                                                  |\n| File Format           | [glTF](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0) |\n| Format Category       | glTF Scenegraph                                                            |\n| Writer Type           | Asynchronous (Synchronous w/ limited functionality)                        |\n| Worker Thread Support | No                                                                         |\n| Streaming Support     | No                                                                         |\n\n## Usage\n\n```js\nimport {GLTFWriter} from '@loaders.gl/gltf';\nimport {encodeSync} from '@loaders.gl/core';\n\nconst arrayBuffer = encodeSync(gltf, GLTFWriter, options);\n```\n\n## Options\n\n- `DracoWriter` - To enable DRACO encoding, the application needs to import and supply the `DracoWriter` class.\n- `DracoLoader` - To enable DRACO encoding, the application needs to import and supply the `DracoLoader` class.\n\n## Attributions\n\nThe `GLTFWriter` was developed for loaders.gl.\n","slug":"docs/api-reference/gltf-loaders/gltf-writer","title":"GLTFWriter"},{"excerpt":"ArrowLoader (Experimental) A simple non-streaming loader for the Apache Arrow columnar table format. Loader Characteristic File Extension…","rawMarkdownBody":"# ArrowLoader (Experimental)\n\nA simple non-streaming loader for the Apache Arrow columnar table format.\n\n| Loader                | Characteristic                                                            |\n| --------------------- | ------------------------------------------------------------------------- |\n| File Extension        | `.arrow`                                                                  |\n| File Type             | Binary                                                                    |\n| File Format           | [IPC: Encapsulated Message Format](http://arrow.apache.org/docs/ipc.html) |\n| Category              | Columnar Table                                                            |\n| Parser Type           | Synchronous                                                               |\n| Worker Thread Support | Yes                                                                       |\n| Streaming Support     | Yes                                                                       |\n\n## Options\n\nN/A\n\n## Background\n\nApache Arrow is an emerging standard for large in-memory columnar data.\n\n## Attributions\n\nArrowLoader development benefitted from extensive technical advice from Paul Taylor @ Graphistry.\n","slug":"docs/api-reference/table-loaders/arrow-loader","title":"ArrowLoader (Experimental)"},{"excerpt":"GLTFScenegraph The  class provides an API for accessing and modifying glTF data. Caveat: Modification of existing binary data chunks has…","rawMarkdownBody":"# GLTFScenegraph\n\nThe `GLTFScenegraph` class provides an API for accessing and modifying glTF data.\n\n> Caveat: Modification of existing binary data chunks has limitations, this class is not intended to be a generic utility for modifying existing glTF data.\n\n## Usage\n\n```js\nimport {GLTFLoader, GLTFScenegraph} from '@loaders.gl/gltf';\nimport {load} from '@loaders.gl/core';\n\n// Load and parse a file\nconst gltfData = await parse(fetch(GLTF_URL), GLTFLoader);\n\n// Create a parser\nconst gltf = new GLTFScenegraph(gltfData);\n\n// Get the complete glTF JSON structure\nconst gltfJson = gltf.getJSON();\n\n// Get specific top-level fields from the glTF JSON chunk\nconst appData = gltf.getApplicationData('customData');\n\n// Get a top level extension from the glTF JSON chunk\nconst topLevelExtension = gltf.getExtension('ORGNAME_extensionName');\nif (topLevelExtension) {\n  ...\n}\n\n// Get images from the binary chunk (together with metadata)\nconst imageIndex = 0;\nconst image = gltf.getImage(imageIndex);\n\n// Get default glTF scenegraph\nconst scenegraph = gltf.getScene();\n// Get specific glTF scenegraph\nconst scenegraph = gltf.getScene(2);\n```\n\n\n## Accessor Methods\n\n### constructor(gltf : Object)\n\nCreates a new `GLTFScenegraph` instance from a pure JavaScript object.\n\n#### json()\n\n#### getApplicationData(key : String) : Object\n\nReturns the given data field in the top-level glTF JSON object.\n\n#### getExtraData(key : String) : Object?\n\nReturns a key in the top-level glTF `extras` JSON object.\n\n#### getExtension(name : String) : Object?\n\nReturns the top-level extension by `name`, if present.\n\n#### getUsedExtensions() : String[]\n\nReturns an array of extension names (covering all extensions used at any level of the glTF hierarchy).\n\n#### getRequiredExtensions() : String[]\n\nReturns an array of extensions at any level of the glTF hierarchy that are required to properly display this file (covering all extensions used at any level of the glTF hierarchy).\n\n#### getObjectExtension(object, extensionName)\n\n\n#### getScene([index : Number]) : Object?\n\nReturns the scene (scenegraph) with the given index, or the default scene if no index is specified.\n\n#### getScene(index : Number) : Object\n\n#### getNode(index : Number) : Object\n\n#### getSkin(index : Number) : Object\n\n#### getMesh(index : Number) : Object\n\n#### getMaterial(index : Number) : Object\n\n#### getAccessor(index : Number) : Object\n\n#### getCamera(index : Number) : Object\n\n#### getTexture(index : Number) : Object\n\n#### getSampler(index : Number) : Object\n\n#### getImage(index : Number) : Object\n\nReturns the image with specified index\n\n#### getBufferView(index : Number) : Object\n\n#### getBuffer(index : Number) : Object\n\n#### getTypedArrayForBufferView(bufferView : Number | Object) : Uint8Array\n\nAccepts buffer view index or buffer view object\n\n#### getTypedArrayForAccessor(accessor : Number | Object) : Uint8Array | Float32Array | ...\n\nAccepts accessor index or accessor object.\n\nReturns a typed array with type that matches the types\n\n#### getTypedArrayForImageData(image : Number | Object) : Uint8Array\n\naccepts accessor index or accessor object\n\n## Modifiers\n\n#### addApplicationData(key, data)\n\nAdd an extra application-defined key to the top-level data structure\n\n#### addExtraData(key, data)\n\n`extras` - Standard GLTF field for storing application specific data\n\nAdd to GLTF top level extension object, mark as used\n\n##### addRequiredExtension(extensionName, data)\n\nAdd GLTF top level extension object, mark as used and required\n\n#### registerUsedExtension(extensionName)\n\nAdd extensionName to list of used extensions\n\n#### registerRequiredExtension(extensionName)\n\nAdd extensionName to list of required extensions\n\n#### removeExtension(extensionName)\n\nRemoves an extension from the top-level list\n\n#### setObjectExtension(object, extensionName, data)\n\n#### addMesh(attributes, indices, mode = 4)\n\n#### addPointCloud(attributes)\n\n#### addBufferView(buffer)\n\nAdd one untyped source buffer, create a matching glTF `bufferView`, and return its index\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n#### addAccessor(bufferViewIndex, accessor)\n\nAdds an accessor to a bufferView\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n#### addImage(imageData, mimeType)\n\nAdds a binary image. Builds glTF \"JSON metadata\" and saves buffer reference\nBuffer will be copied into BIN chunk during \"pack\"\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n#### createBinChunk()\n\nPacks any pending binary data into the first binary glTF buffer.\n\nNote: Overwrites the existing first buffer if present.\n","slug":"docs/api-reference/gltf-loaders/gltf-scenegraph","title":"GLTFScenegraph"},{"excerpt":"Table Category (Experimental) Table Types loaders.gl deals with (and offers utilities to convert between) three different types of tables…","rawMarkdownBody":"# Table Category (Experimental)\n\n## Table Types\n\nloaders.gl deals with (and offers utilities to convert between) three different types of tables:\n\n### Classic Tables (Row-Major)\n\nThis is the classic JavaScript table that consists of an `Array` of `Object` instances. It would be the natural output of e.g. a JSON loader or a YAML loader.\n\n### Columnar Tables (Column-Major)\n\nColumnar tables are stored as one array per column. Columns that are numeric can be loaded as typed arrays which are stored in contigous memory.\n\nContiguous memory has tremendous benefits:\n\n- Values are adjacent in memory, the resulting cache locality can result in big performance gains\n- Typed arrays can of course be efficiently transferred from worker threads to main thread\n- Can be directly uploaded to the GPU for further processing.\n\n### Chunked Columnar Tables\n\nA problem with columnar tables is that column arrays they can get very long, causing issues with streaming, memory allication etc. A powerful solution is to worked with chunked columnar tables, where columns is are broken into matching sequences of typed arrays.\n\nThe down-side is that complexity can increase quickly and it is best to use helper libraries (such as Apache Arrow) to manage the necessary data structures and book-keeping.\n\n### DataFrames (Arrow)\n\nData Frames are optimized to minimize the amount of copying/moving/reallocation of data during common operations such e.g. loading and transformations, and support zero-cost filtering through smart iterators etc.\n\nUsing the Arrow API it is possible to work extremely efficiently with very large (multi-gigabyte) datasets.\n\n## Table Schemas\n\nFor certain operations, it is useful to have a schema that describes the columns in the table. loaders.gl defines a simple schema object, as follows\n\n## Utilities\n\nA set of utilities is provided.\n\n- `deduceTableSchema(table)` - returns a schema object, autodeduced from columnar or other tables\n-\n","slug":"docs/api-reference/table-loaders/category-table","title":"Table Category (Experimental)"},{"excerpt":"Loader Object Specification To be compatible with the parsing/loading functions in  such as  and , a parser needs to be described by a…","rawMarkdownBody":"# Loader Object Specification\n\nTo be compatible with the parsing/loading functions in `@loaders.gl/core` such as `parse` and `load`, a parser needs to be described by a \"loader object\" conforming to the following specification.\n\n## Loader Object Format v1.0\n\n### Common Fields\n\n| Field        | Type       | Default  | Description                                                     |\n| ------------ | ---------- | -------- | --------------------------------------------------------------- |\n| `name`       | `String`   | Required | Short name of the loader ('OBJ', 'PLY' etc)                     |\n| `extension`  | `String`   | Required | Three letter (typically) extension used by files of this format |\n| `extensions` | `String[]` | Required | Array of file extension strings supported by this loader        |\n| `category`   | `String`   | Optional | Indicates the type/shape of data                                |\n\nNote: Only one of `extension` or `extensions` is required. If both are supplied, `extensions` will be used.\n\n### Test Function\n\n| Field      | Type       | Default | Description                                                                       |\n| ---------- | ---------- | ------- | --------------------------------------------------------------------------------- |\n| `test` | `Function`|`String`|`String[]` | `null`  | Guesses if a binary format file is of this format by examining the first bytes in the file. If the test is specified as a string or array of strings, the initial bytes are expected to be \"magic bytes\" matching one of the provided strings. |\n| `testText` | `Function` | `null`  | Guesses if a text format file is of this format by examining the first characters in the file |\n\n### Parser Function\n\nWhen creating a new loader object, at least one of the parser functions needs to be defined.\n\n| Parser function field               | Type       | Default | Description                                                                            |\n| ----------------------------------- | ---------- | ------- | -------------------------------------------------------------------------------------- |\n| `parseInBatches` (Experimental)     | `Function` | `null`  | Parses binary data chunks (`ArrayBuffer`) to output data \"batches\"                     |\n| `parseInBatchesSync` (Experimental) | `Function` | `null`  | Synchronously parses binary data chunks (`ArrayBuffer`) to output data \"batches\"       |\n| `parseSync`                         | `Function` | `null`  | Atomically and synchronously parses binary data (e.g. file contents) (`ArrayBuffer`)   |\n| `parseTextSync`                     | `Function` | `null`  | Atomically and synchronously parses a text file (`String`)                             |\n| `parse`                             | `Function` | `null`  | Asynchronously parses binary data (e.g. file contents) asynchronously (`ArrayBuffer`). |\n| `loadAndParse`                      | `Function` | `null`  | Asynchronously reads a binary file and parses its contents.                            |\n\nNote: Only one parser function is required. Synchronous parsers are more flexible as they can support synchronous parsing in addition to asynchronous parsing, and iterator-based parsers are more flexible as they can support batched loading in addition to atomic loading. You are encouraged to provide the most capable parser function you can (e.g. `parseSync` or `parseToIterator` if possible). Unless you are writing a completely new loader, the appropriate choice usually depends on the loader you are encapsulating.\n","slug":"docs/api-reference/specifications/loader-object-format","title":"Loader Object Specification"},{"excerpt":"CSVLoader (Experimental) Streaming loader for comma-separated value and delimiter-separated value encoded files. Loader Characteristic File…","rawMarkdownBody":"# CSVLoader (Experimental)\n\nStreaming loader for comma-separated value and [delimiter-separated value](https://en.wikipedia.org/wiki/Delimiter-separated_values) encoded files.\n\n| Loader                | Characteristic                                 |\n| --------------------- | ---------------------------------------------- |\n| File Extension        | `.csv`, `.dsv`                                 |\n| File Type             | Text                                           |\n| File Format           | [RFC4180](https://tools.ietf.org/html/rfc4180) |\n| Category              | Table                                          |\n| Parser Type           | Asynchronous                                   |\n| Worker Thread Support | Yes                                            |\n| Streaming Support     | Yes                                            |\n\n## Options\n\nThe following options are passed on to [papaparse](https://www.papaparse.com/docs#config):\n\n| Option                   | Description                                                                                                                                                                                                                                                                                     |\n| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `delimiter`=             | The delimiting character. By default auto-detects from a list of common delimiters (or `delimitersToGuess`).                                                                                                                                                                                    |\n| `newline`=               | The newline sequence. By default auto-detects. Must be `\\r`, `\\n`, or `\\r\\n`.                                                                                                                                                                                                                   |\n| `quoteChar`=`\"`          | The character used to quote fields. (Note: unquoted fields are parsed correctly).                                                                                                                                                                                                               |\n| `escapeChar`=`\"`         | The character used to escape the quote character within a field.                                                                                                                                                                                                                                |\n| `dynamicTyping`=`true`   | If true, numeric and boolean data values will be converted to their type (instead if strings).                                                                                                                                                                                                  |\n| `preview`=`0`            | If > 0, only that many rows will be parsed.                                                                                                                                                                                                                                                     |\n| `encoding`=              | The encoding to use when reading files. Defaults to UTF8.                                                                                                                                                                                                                                       |\n| `comments`=`false`       | A string that indicates a comment (for example, \"#\" or \"//\"). When Papa encounters a line starting with this string, it will skip the line.                                                                                                                                                     |\n| `skipEmptyLines`=`false` | If `true`, lines that are completely empty (those which evaluate to an empty string) will be skipped. If set to 'greedy', lines that don't have any content (those which have only whitespace after parsing) will also be skipped.                                                              |\n| `transform`              | A function to apply on each value. The function receives the value as its first argument and the column number or header name when enabled as its second argument. The return value of the function will replace the value it received. The transform function is applied before dynamicTyping. |\n| `delimitersToGuess`=     | An array of delimiters to guess from if the delimiter option is not set. Default is `[',', '\\t', '|', ';', Papa.RECORD_SEP, Papa.UNIT_SEP]`                                                                                                                                                     |\n| `fastMode`=              | Force set \"fast mode\". Fast mode speeds up parsing significantly for large inputs but only works when the input has no quoted fields. Fast mode will be auto enabled if no \" characters appear in the input.                                                                                    |\n\nNotes:\n\nNote that the following `papaparse` options are NOT supported by `CSVLoader` (they are either already used internally or they interfere with the more flexible data loading and parsing model used by `loaders.gl`):\n\n| Option             | Description                                                                  | Reason/Replacement                                                              |\n| ------------------ | ---------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| `header`=`false`   | If true, the first row of parsed data will be interpreted as field names. \\* | Header is detected and parsed by `CSVLoader`                                    |\n| `transformHeader`= | Function to apply on each header.                                            | (Only available in version 5.0)                                                 |\n| `worker`           | Whether to use a worker thread.                                              | Use `CSVWorkerLoader` instead.                                                  |\n| `step`             | Callback function for streaming.                                             | Use `loadInBatches` instead.                                                    |\n| `complete`         | Callback function for streaming.                                             | Use `loadInBatches` instead.                                                    |\n| `error`            | Callback function for error.                                                 | Errors will be handled by `CSVLoader`.                                          |\n| `download`         | First argument is URL from which to download a file.                         | Use external functions to load data (such as `fetch` or `fetchFile`).           |\n| `chunk`            | Callback executed after every chunk is loaded.                               | Use `loadInBatches` instead.                                                    |\n| `beforeFirstChunk` | Callback executed before parsing of first chunk.                             | Use `loadInBatches` instead.                                                    |\n| `withCredentials`  | `XMLHttpRequest.withCredentials` property.                                   | Control credentials using your loading functions (e.g. `fetch` or `fetchFile`). |\n\n## Attributions\n\nCSVLoader is based on a minimal fork of the [papaparse](https://github.com/mholt/PapaParse) module, under MIT license.\n","slug":"docs/api-reference/table-loaders/csv-loader","title":"CSVLoader (Experimental)"},{"excerpt":"Writer Object Specification To be compatible with  functions such as , writer objects need to conform to the following specification: Common…","rawMarkdownBody":"# Writer Object Specification\n\nTo be compatible with `@loaders.gl/core` functions such as `encode`, writer objects need to conform to the following specification:\n\n### Common Fields\n\n| Field       | Type     | Default  | Description                                                     |\n| ----------- | -------- | -------- | --------------------------------------------------------------- |\n| `name`      | `String` | Required | Short name of the loader ('OBJ', 'PLY' etc)                     |\n| `extension` | `String` | Required | Three letter (typically) extension used by files of this format |\n| `category`  | `String` | Optional | Indicates the type/shape of data                                |\n\n### Encoder Function\n\n| Field                            | Type       | Default | Description                                            |\n| -------------------------------- | ---------- | ------- | ------------------------------------------------------ |\n| `encodeSync`                     | `Function` | `null`  | Encodes synchronously                                  |\n| `encode`                         | `Function` | `null`  | Encodes asynchronously                                 |\n| `encodeInBatches` (Experimental) | `Function` | `null`  | Encodes and releases batches through an async iterator |\n\nNote: The format of the input data to the encoders depends on the loader. Several loader categories are defined to provided standardized data formats for similar loaders.\n","slug":"docs/api-reference/specifications/writer-object-format","title":"Writer Object Specification"},{"excerpt":"ArrayBuffers loaders.gl API consistently uses ArrayBuffers to represent and transport binary data. Why ArrayBuffers? One of the design goals…","rawMarkdownBody":"# ArrayBuffers\n\nloaders.gl API consistently uses ArrayBuffers to represent and transport binary data.\n\n## Why ArrayBuffers?\n\nOne of the design goals of loaders.gl is to provide applications with a single, consistent API that works across (reasonably modern) browsers, worker threads and Node.js. One of the characteristics of this API is how binary data is represented.\n\nloaders.gl \"standardizes\" on ArrayBuffers for a number of reasons:\n\n- ArrayBuffers are the \"canonical\" input format for the WebGL API, allowing efficient uploads of large binary data sets to the GPU.\n- ArrayBuffers allow ownership to be transferred between threads (Browser Main Thread and WebWorkers), massively improving performance when parsing on loaders.\n- ArrayBuffers are used to transport raw data and most newer JavaScript APIs rely on them, including WebSockets, Web Intents, XMLHttpRequest version 2 etc.\n- ArrayBuffers are well supported by recent Node.js versions, in fact the traditional Node.js `Buffer` class is now backed by an `ArrayBuffer`.\n\n## ArrayBuffers and Typed Arrays\n\nRecall that typed arrays (e.g. `Float32Array`) are just views into array buffers. Every typed array has a `buffer` reference.\n\nMany loaders.gl functions directly accept typed arrays.\n\nCaveat: typed arrays that are partial views (e.g. with offsets) sometimes need special handling in the application.\n\n## Converting between ArrayBuffers and Strings\n\nUse `TextEncoder` and `TextDecoder` in the JavaScript [string encoding/decoding library](https://github.com/inexorabletash/text-encoding).\n\nSince these classes are central to using ArrayBuffers correctly, loaders.gl re-exports these symbols, transparently polyfilling them under Node.js.\n\n## Converting between ArrayBuffers and other Binary Formats.\n\nWhile standardizing on ArrayBuffers helps streamline the loaders.gl API and application code, occaionally applications need to interface with APIs that accept other binary data types/formats. To support this case, loaders.gl provides a small set of utilities (non-exhaustive) for converting from and to other binary JavaScript types/formats, e.g. `toArrayBuffer`:\n\nBinary formats in JS:\n\n- ArrayBuffer\n- Uint8Array\n- Blob\n- nodejs Buffer\n\nExamples of semi-\"binary\" formats in JS:\n\n- array: Array of bytes (numbers between 0 and 255).\n- string (binary): string in “binary” form, 1 byte per char (2 bytes).\n- string (base64): string containing the binary data encoded in a base64 form.\n\n## Utilities\n\n- [BufferReader/BufferWriter](https://github.com/yuntonyx/arraybuffer-utils) - Helps keep track of current position when working with DataView's through a tightly packed binary object.\n","slug":"docs/developer-guide/concepts/array-buffers","title":"ArrayBuffers"},{"excerpt":"AsyncIterators Streaming functionality in loaders.gl is built on the ES2018  concept. This page gives some background on AsyncIterator since…","rawMarkdownBody":"# AsyncIterators\n\nStreaming functionality in loaders.gl is built on the ES2018 `AsyncIterator` concept. This page gives some background on AsyncIterator since it is a recently introduced concept (at least as part of the JavaScript standard).\n\n## Availability\n\n`AsyncIterator` is a standard JavaScript ES2018 feature and is well supported by recent evergreen browsers and Node.js versions.\n\nThe `for await of` iteration syntax is supported as well as the babel transpiler.\n\n## Batched Parsing and Endcoding using AsyncIterators\n\nThe input and output from streaming loaders and writers can both be expressed in terms of async iterators.\n\n## Using AsyncIterator\n\nRemember tyhat an async iterator can be consumed (iterated over) via the for-await construct:\n\n```js\nfor await (const x of asyncIterable) {}\n```\n\n## Using Streams as AsyncIterators\n\nWith a little effort, streams in JavaScript can be treated as AsyncIterators. As the section about [Javascript Streams](docs/developer-guide/streams.md) explains, instead of registering callbacks on the stream, you can now work with streams in this way:\n\n```js\nfor await (const buf of fs.createReadStream('foo.txt')) {\n  // do something\n}\n```\n\n## Creating AsyncIterators\n\nRemember that any object in JavaScript that implements the `[Symbol.asyncIterator]()` method is an `AsyncIterable`. And the async generator syntax can be used to generate new async iterators\n\n```js\nasync function* asyncIterator() {\n  yield new Promise(...)\n}\n\nfor await (const x of asyncIterator()) {} // Notice parens after 'asyncIterator'\n```\n","slug":"docs/developer-guide/concepts/async-iterators","title":"AsyncIterators"},{"excerpt":"Streaming Streaming support in loaders.gl is a work-in-progress. The ambition is that many loaders would support streaming from both Node…","rawMarkdownBody":"# Streaming\n\n> Streaming support in loaders.gl is a work-in-progress. The ambition is that many loaders would support streaming from both Node and DOM streams, through a consistent API and set of conventions (for both applications and loader/writer objects).\n\n## Streaming Loads\n\n### Incremental Parsing\n\nSome loaders offer incremental parsing (chunks of incomplete data can be parsed, and updates will be sent after a certain batch size has been exceeded). In many cases, parsing is fast compared to loading of data, so incremental parsing on its own may not provide a lot of value for applications.\n\n### Incremental Loading\n\nIncremental parsing becomes more interesting when it can be powered by incremental loading, whether through request updates or streams (see below).\n\n### Streamed Loading\n\nStreamed loading means that the entire data does not need to be loaded.\n\nThis is particularly advantageous when:\n\n- loading files with sizes that exceed browser limits (e.g. 1GB in Chrome)\n- doing local processing to files (tranforming one row at a time), this allows pipe constructions that can process files that far exceed internal memory.\n\n## Batched Updates\n\nFor incemental loading and parsing to be really effective, the application needs to be able to deal efficiently with partial batches as they arrive. Each loader category (or loader) may define a batch update conventions that are appropriate for the format being loaded.\n\n## Streaming Writes\n\nTBA\n\n## Node Streams vs DOM Streams\n\nStream support is finally arriving in browsers, however DOM Streams have a slightly different API than Node streams and the support across browsers is still spotty.\n\n## Polyfills\n\nStream support across browsers can be somewhat improved with polyfills. TBA\n\n## Stream Utilities\n\n- Stream to memory, ...\n- Automatically create stream if loader/writer only supports streaming\n- ...\n","slug":"docs/developer-guide/concepts/streaming","title":"Streaming"},{"excerpt":"Worker Threads Reasons for moving loading to workers: When parsing is CPU heavy, the browser main thread can become blocked, freezing the…","rawMarkdownBody":"# Worker Threads\n\nReasons for moving loading to workers:\n\n- When parsing is CPU heavy, the browser main thread can become blocked, freezing the application until parsing completes.\n- Leverage multi-core CPUs when parsing multiple data items.\n\nConsiderations when moving loading and parsing to workers:\n\n- Data Transfer - Serializing/deserializing when transferring resuls back to main thread can more than defeat gains from loading on a separate thread.\n- Data Types - Due to data transfer issues there are constraints on what data types are appropriate\n- Configuration - Creating workers can require build system setup/configuration.\n- Message Passing - Parsing on workers requires message passing between threads. While simple it can add clutter to application code.\n- Debugging - Worker based code can be somewhat harder to debug. Being able to move the code back to the main thread can help.\n- Startup Times - Worker startup times can defeat speed gains from parsing on workers.\n- Thread Pool Management (TBA) -\n\n## Data Transfer\n\nThreads cannot share non-binary data structures and these have to be serialized/deserialized. This is a big issue for worker thread based loading as the purpose of loaders is typically to load and parse big datastructures, and main thread deserialization times are often comparable to or even exceed the time required to parse the data in the first place, defeating the value of moving parsing to a worker thread.\n\nThe solution is usually to use data types that support ownership transfer (see next section) as much as possible and minimize the amount of non-binary data returned from the parser.\n\n## Data Types\n\nJavaScript ArrayBuffers and Typed Arrays can be passed with minimal overhead (ownership transfer) and the value of worker based parsing usually depends on whether the loaded data can (mostly) be stored in these types.\n\n## Message Passing\n\nloaders.gl will handle message passing behind the scenes. Loading on a worker thread returns a promise that completes when the worker is done and the data has been transferred back to the main thread.\n\n## Build Configuration\n\nAll worker enabled loaders come with a pre-built, minimal worker \"executable\" to enable zero-configuration use in applications.\n\n## Bundle size concerns\n\nAll worker enabled loaders provide separate loader objects to ensure that tree-shaking bundlers will be able to remove the code for the unused case.\n\n## Debugging and Benchmarking\n\nLoaders.gl offers loader objects for main thread and worker threads. A simple switch lets you move your loading back to the main thread for easier debugging and benchmarking (comparing speeds to ensure you are gaining the benefits you expect from worker thread based loading).\n\n## Startup Times (TBA)\n\nThrough Thread Pool Management it will be possible to start worker threads before they ae needed to minimize worker loading delay when parsing.\n\n## Thread Pool Management (TBA)\n\nIt can be valuable to run muliple instances of the same worker thread to leverage multi-core CPUs. Being able to warm-up (pre-iniutilize) the thread pool and set limits of how many threads of each worker type...\n","slug":"docs/developer-guide/concepts/worker-threads","title":"Worker Threads"},{"excerpt":"@math.gl/geospatial This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes. This…","rawMarkdownBody":"# @math.gl/geospatial\n\n> This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes.\n\nThis modile provides classes and utilities to facilitate working with the major geospatial coordinate systems and projections used with computer maps, primarily:\n- [WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System) (World Geodetic System) coordinates.\n- [Web Mercator Projection](https://en.wikipedia.org/wiki/Web_Mercator_projection)\n\n## Class Overview\n\n| Class                   | Dewscription |\n| ---                     | --- |\n| `Ellipsoid`             | Implements ellipsoid |\n| `Ellipsoid.WSG84`       | An `Ellipsoid` instance initialized with Earth radii per WGS84. |\n| `CartographicRectangle` | A rectangle defined by cartographic longitudes and latitudes. |\n\n## Usage Examples\n\nA major use of this library is to convert between \"cartesian\" (`x`, `y`, `z`) and \"cartographic\" (`longitude`, `latitude`, `height`) representations of WSG84 coordinates. The `Ellipsoid` class implements these calculations.\n\n\n## Framework Independence\n\nLike all non-core math.gl modules, this library can be used without the math.gl core classes.\n\n- Any input vectors can be supplied as length 3 JavaScript `Array` instances.\n- Any result vectors can be treated as length 3 JavaScript `Array` instances (they may be math.gl `Vector3`).\n- The core math.gl classes inherit from JavaScript `Array` and can be used directly as input.\n","slug":"docs/api-reference/math/geospatial","title":"@math.gl/geospatial"},{"excerpt":"CartographicRectangle A two dimensional region specified as longitude and latitude coordinates. Usage Creates a rectangle given the boundary…","rawMarkdownBody":"# CartographicRectangle\n\nA two dimensional region specified as longitude and latitude coordinates.\n\n\n## Usage\n\nCreates a rectangle given the boundary longitude and latitude in degrees.\n```js\nconst rectangle = CartographicRectangle.fromDegrees(0.0, 20.0, 10.0, 30.0);\n```\n\nCreates a rectangle given the boundary longitude and latitude in radians.\n```js\nconst rectangle = CartographicRectangle.fromRadians(0.0, Math.PI/4, Math.PI/8, 3*Math.PI/4);\n```\n\n## Static Members\n\n### CartographicRectangle.MAX_VALUE\n\nnew CartographicRectangle(-Math.PI, -CesiumMath.PI_OVER_TWO, Math.PI, CesiumMath.PI_OVER_TWO));\n\n## Members\n\n##### west : Number\n\nThe westernmost longitude in radians in the range [-Pi, Pi].\n\ndefault 0.0\n\n##### south : Number\n\nThe southernmost latitude in radians in the range [-Pi/2, Pi/2].\n\ndefault 0.0\n\n##### east : Number\n\nThe easternmost longitude in radians in the range [-Pi, Pi].\n\ndefault 0.0\n\n##### north : Number\n\nThe northernmost latitude in radians in the range [-Pi/2, Pi/2].\n\ndefault 0.0\n\n\n## Methods\n\n##### constructor(west, south, east, north)\n\n- `west`=`0.0`  The westernmost longitude, in radians, in the range [-Pi, Pi].\n- `south`=`0.0`  The southernmost latitude, in radians, in the range [-Pi/2, Pi/2].\n- `east`=`0.0`  The easternmost longitude, in radians, in the range [-Pi, Pi].\n- `north`=`0.0`  The northernmost latitude, in radians, in the range [-Pi/2, Pi/2].\n\n\n##### computeWidth()\n\nComputes the width of a rectangle in radians.\n\n@returns {Number} The width.\n\n##### computeHeight()\n\nComputes the height of a rectangle in radians.\n\n@returns {Number} The height.\n\n##### fromDegrees(west, south, east, north, result)\n\nCreates a rectangle given the boundary longitude and latitude in degrees.\n\n@param {Number} [west=0.0] The westernmost longitude in degrees in the range [-180.0, 180.0].\n@param {Number} [south=0.0] The southernmost latitude in degrees in the range [-90.0, 90.0].\n@param {Number} [east=0.0] The easternmost longitude in degrees in the range [-180.0, 180.0].\n@param {Number} [north=0.0] The northernmost latitude in degrees in the range [-90.0, 90.0].\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n##### fromRadians(west, south, east, north, result)\n\nCreates a rectangle given the boundary longitude and latitude in radians.\n\n@param {Number} [west=0.0] The westernmost longitude in radians in the range [-Math.PI, Math.PI].\n@param {Number} [south=0.0] The southernmost latitude in radians in the range [-Math.PI/2, Math.PI/2].\n@param {Number} [east=0.0] The easternmost longitude in radians in the range [-Math.PI, Math.PI].\n@param {Number} [north=0.0] The northernmost latitude in radians in the range [-Math.PI/2, Math.PI/2].\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n\n##### fromCartographicArray(cartographics, result)\n\nCreates the smallest possible CartographicRectangle that encloses all positions in the provided array.\n\n@param {Cartographic[]} cartographics The list of Cartographic instances.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n##### fromCartesianArray(cartesians, ellipsoid, result)\n\nCreates the smallest possible CartographicRectangle that encloses all positions in the provided array.\n\n@param {Cartesian3[]} cartesians The list of Cartesian instances.\n@param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid the cartesians are on.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n##### clone(rectangle, result)\n\nDuplicates a CartographicRectangle.\n\n@param {CartographicRectangle} rectangle The rectangle to clone.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided. (Returns undefined if rectangle is undefined)\n\n\nCompares the provided CartographicRectangles componentwise and returns\n`true` if they pass an absolute or relative tolerance test,\n`false` otherwise.\n\n@param {CartographicRectangle} [left] The first CartographicRectangle.\n@param {CartographicRectangle} [right] The second CartographicRectangle.\n@param {Number} absoluteEpsilon The absolute epsilon tolerance to use for equality testing.\n@returns {Boolean} `true` if left and right are within the provided epsilon, `false` otherwise.\n/\n\tCartographicRectangle.equalsEpsilon = function(left, right, absoluteEpsilon)\n\t\t//>>includeStart('debug', pragmas.debug);\n\t\tCheck.typeOf.number('absoluteEpsilon', absoluteEpsilon);\n\t\t//>>includeEnd('debug');\n\n\t\treturn (left === right) ||\n\t\t\t   (defined(left) &&\n\t\t\t\tdefined(right) &&\n\t\t\t\t(Math.abs(left.west - right.west) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.south - right.south) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.east - right.east) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.north - right.north) <= absoluteEpsilon));\n\t};\n\n\nDuplicates this CartographicRectangle.\n\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n/\n\tCartographicRectangle.prototype.clone = function(result)\n\t\treturn CartographicRectangle.clone(this, result);\n\t};\n\n\nCompares the provided CartographicRectangle with this CartographicRectangle componentwise and returns\n`true` if they are equal, `false` otherwise.\n\n@param {CartographicRectangle} [other] The CartographicRectangle to compare.\n@returns {Boolean} `true` if the CartographicRectangles are equal, `false` otherwise.\n/\n\tCartographicRectangle.prototype.equals = function(other)\n\t\treturn CartographicRectangle.equals(this, other);\n\t};\n\n\nCompares the provided rectangles and returns `true` if they are equal,\n`false` otherwise.\n\nCartographicRectangle.equals = function(left, right)\n\n@param {CartographicRectangle} [left] The first CartographicRectangle.\n@param {CartographicRectangle} [right] The second CartographicRectangle.\n@returns {Boolean} `true` if left and right are equal; otherwise `false`.\n\n\nCompares the provided CartographicRectangle with this CartographicRectangle componentwise and returns\n`true` if they are within the provided epsilon,\n`false` otherwise.\n\nCartographicRectangle.prototype.equalsEpsilon = function(other, epsilon)\n\n@param {CartographicRectangle} [other] The CartographicRectangle to compare.\n@param {Number} epsilon The epsilon to use for equality testing.\n@returns {Boolean} `true` if the CartographicRectangles are within the provided epsilon, `false` otherwise.\n\n##### validate()\n\nChecks a CartographicRectangle's properties and throws if they are not in valid ranges.\n\nThrows\n- `north` must be in the interval [`-Pi/2`, `Pi/2`].\n- `south` must be in the interval [`-Pi/2`, `Pi/2`].\n- `east` must be in the interval [`-Pi`, `Pi`].\n- `west` must be in the interval [`-Pi`, `Pi`].\n\n##### southwest(rectangle, result)\n\nComputes the southwest corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n##### northwest(rectangle, result)\n\nComputes the northwest corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n##### northeast(rectangle, result)\n\nComputes the northeast corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n\n##### southeast(rectangle, result)\n\nComputes the southeast corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n##### center = function(rectangle, result)\n\nComputes the center of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the center\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n##### intersection = function(rectangle, CartographicotherRectangle, result)\n\nComputes the intersection of two rectangles.  This function assumes that the rectangle's coordinates are\nlatitude and longitude in radians and produces a correct intersection, taking into account the fact that\nthe same angle can be represented with multiple values as well as the wrapping of longitude at the\nanti-meridian.  For a simple intersection that ignores these factors and can be used with projected\ncoordinates, see {@link CartographicRectangle.simpleIntersection}.\n\n@param {CartographicRectangle} rectangle On rectangle to find an intersection\n@param {CartographicRectangle} CartographicotherRectangle Another rectangle to find an intersection\n@param {CartographicRectangle} [result] The object onto which to store the result.\n\n\n##### simpleIntersection = function(rectangle, CartographicotherRectangle, result)\n\nComputes a simple intersection of two rectangles.  Unlike {@link CartographicRectangle.intersection}, this function\ndoes not attempt to put the angular coordinates into a consistent range or to account for crossing the\nanti-meridian.  As such, it can be used for rectangles where the coordinates are not simply latitude\nand longitude (i.e. projected coordinates).\n\n@param {CartographicRectangle} rectangle On rectangle to find an intersection\n@param {CartographicRectangle} CartographicotherRectangle Another rectangle to find an intersection\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle|undefined} The modified result parameter, a new CartographicRectangle instance if none was provided or undefined if there is no intersection.\n\n\n##### union(rectangle, CartographicotherRectangle, result)\n\nComputes a rectangle that is the union of two rectangles.\n\n@param {CartographicRectangle} rectangle A rectangle to enclose in rectangle.\n@param {CartographicRectangle} CartographicotherRectangle A rectangle to enclose in a rectangle.\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n##### expand(rectangle, cartographic, result)\n\nComputes a rectangle by enlarging the provided rectangle until it contains the provided cartographic.\n\n@param {CartographicRectangle} rectangle A rectangle to expand.\n@param {Cartographic} cartographic A cartographic to enclose in a rectangle.\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if one was not provided.\n\n##### contains(rectangle, cartographic)\n\nReturns true if the cartographic is on or inside the rectangle, false otherwise.\n\n@param {CartographicRectangle} rectangle The rectangle\n@param {Cartographic} cartographic The cartographic to test.\n@returns {Boolean} true if the provided cartographic is inside the rectangle, false otherwise.\n\n##### subsample(rectangle, ellipsoid, surfaceHeight, result)\n\nSamples a rectangle so that it includes a list of Cartesian points suitable for passing to\n{@link BoundingSphere#fromPoints}.  Sampling is necessary to account\nfor rectangles that cover the poles or cross the equator.\n\n@param {CartographicRectangle} rectangle The rectangle to subsample.\n@param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid to use.\n@param {Number} [surfaceHeight=0.0] The height of the rectangle above the ellipsoid.\n@param {Cartesian3[]} [result] The array of Cartesians onto which to store the result.\n@returns {Cartesian3[]} The modified result parameter or a new Array of Cartesians instances if none was provided.\n\n\nThe largest possible rectangle.\n\n","slug":"docs/api-reference/math/geospatial/cartographic-rectangle","title":"CartographicRectangle"},{"excerpt":"Cartographic A class with static function to help convert geospatial coordinates, primarily in WSG84 notation, between lng/lat/height and…","rawMarkdownBody":"# Cartographic\n\nA class with static function to help convert geospatial coordinates, primarily in [WSG84](https://en.wikipedia.org/wiki/World_Geodetic_System) notation, between lng/lat/height and _cartesian_ (earth-center relative `x`,`y`,`z`) coordinates.\n\n## Usage\n\nConvert Cartesian coordinate to longitude/latitude/height-over-ellipsoid.\n\n```js\nconst lnglatz = Cartographic.fromCartesian([-115.0, 37.0]);\n```\n\nConvert longitude/latitude/height-over-ellipsoid to Cartesian:\n\n```js\nconst position = Cartographic.fromDegrees([-115.0, 37.0]);\n```\n\nConvert lng/lat/z with long lat in degrees to radians.\n\n```js\nconst position = Cartographic.toRadians([-2.007, 0.645]);\n```\n\nConvert lng/lat/z with long lat in radians to degrees.\n\n```js\nconst position = Cartographic.toDegrees([-2.007, 0.645]);\n```\n\n## Static Methods\n\n### Cartographic.toRadians([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]) : Number[3]\n\nReturns a new `Vector3` from longitude and latitude values given in degrees.\n\n- `longitude` The longitude, in degrees\n- `latitude` The latitude, in degrees\n- `height`=`0.0` The height, in meters, above the ellipsoid.\n- `result`= The object onto which to store the result.\n\n### Cartographic.toDegrees([longitudeRadians : Number, latitudeRadians : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nReturns a Vector3 position from longitude and latitude values given in radians.\n\n- `longitude` The longitude, in degrees\n- `latitude` The latitude, in degrees\n- `height`=`0.0` The height, in meters, above the ellipsoid.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.- `result`= The object onto which to store the result.\n\n### Cartographic.fromCartesian([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nConverts a Cartesian geodetic position to a longitude/latitude/height vector.\n\n- @param {Vector3} cartesian The Cartesian position to convert to cartographic representation.\n- @param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid on which the position lies.\n- @param {Cartographic} [result] The object onto which to store the result.\n- @returns {Cartographic} The modified result parameter, new Cartographic instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\nReturns:\n\n- a lng, lat, height from a Cartesian position. The values in the resulting object will be in radians.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.\n- `result` The object onto which to store the result.\n\nReturns:\n\n- Array of 3 numbers. The modified result parameter, a new vector if none was provided, or `undefined` if the cartesian is at the center of the ellipsoid.\n\n### Cartographic.toCartesian([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nConverts a lng/lat/height into a Cartesian position on the given ellipsoid.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.\n- `result` The object onto which to store the result.\n\nReturns:\n\n- The modified result parameter, new Cartographic instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\nThe values in the resulting object will be in degrees.\n\n## Attribution\n\nThis class is based on [Cesium](https://github.com/AnalyticalGraphicsInc/cesium) source code under the Apache 2 License.\n","slug":"docs/api-reference/math/geospatial/cartographic","title":"Cartographic"},{"excerpt":"Ellipsoid A quadratic surface defined in Cartesian coordinates by the equation . Primarily used to represent the shape of planetary bodies…","rawMarkdownBody":"# Ellipsoid\n\nA quadratic surface defined in Cartesian coordinates by the equation `(x / a)^2 + (y / b)^2 + (z / c)^2 = 1`. Primarily used to represent the shape of planetary bodies.\n\nThe main use of this class is to convert between the \"cartesian\" and \"cartographic\" coordinate systems.\n\nRather than constructing this object directly, one of the provided constants is used.\n\n## Usage\n\nCreate a Cartographic and determine it's Cartesian representation on a WGS84 ellipsoid.\n\n```js\nconst cartographicPosition = [Math.toRadians(21), Math.toRadians(78), 5000];\nconst cartesianPosition = Ellipsoid.WGS84.cartographicToCartesian(position);\n```\n\n```js\nconst cartesianPosition = new [17832.12, 83234.52, 952313.73];\nconst cartographicPosition = Ellipsoid.WGS84.cartesianToCartographic(position);\n```\n\n## Static Fields\n\n#### Ellipsoid.WGS84 : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to the WGS84 standard.\n\n#### Ellipsoid.UNIT_SPHERE : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to radii of (1.0, 1.0, 1.0).\n\n#### Ellipsoid.MOON : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to a sphere with the lunar radius.\n\n## Members\n\n#### radii : Vector3 (readonly)\n\nGets the radii of the ellipsoid.\n\n#### radiiSquared : Vector3 (readonly)\n\nGets the squared radii of the ellipsoid.\n\n#### radiiToTheFourth : Vector3 (readonly)\n\nGets the radii of the ellipsoid raise to the fourth power.\n\n#### oneOverRadii : Vector3 (readonly)\n\nGets one over the radii of the ellipsoid.\n\n#### oneOverRadiiSquared : Vector3 (readonly)\n\nGets one over the squared radii of the ellipsoid.\n\n#### minimumRadius : Number (readonly)\n\nGets the minimum radius of the ellipsoid.\n\n#### maximumRadius : Number\n\nGets the maximum radius of the ellipsoid.\n\n## Methods\n\n#### constructor(x : Number, y : Number, z : Number)\n\n- `x`=`0` The radius in the x direction.\n- `y`=`0` The radius in the y direction.\n- `z`=`0` The radius in the z direction.\n\nThrows\n\n- All radii components must be greater than or equal to zero.\n\n#### clone() : Ellipsoid\n\nDuplicates an Ellipsoid instance.\n\n- {Ellipsoid} [result] Optional object onto which to store the result, or undefined if a new\n  instance should be created.\n\nReturns\n- The cloned Ellipsoid. (Returns undefined if ellipsoid is undefined)\n\n#### equals(right)\n\nCompares this Ellipsoid against the provided Ellipsoid componentwise and returns `true` if they are equal, `false` otherwise. \\*\n\n- {Ellipsoid} [right] The other Ellipsoid. used.\n\nReturns - {Boolean} `true` if they are equal, `false` otherwise.\n\n#### toString() : String\n\nCreates a string representing this Ellipsoid in the format  used.'(radii.x, radii.y, radii.z)'. \\*\n\nReturns\n\n- A string representing this ellipsoid in the format '(radii.x, radii.y, radii.z)'.\n\n#### geocentricSurfaceNormal(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the unit vector directed from the center of this ellipsoid toward the provided Cartesian position.\n\n- `cartesian` - The WSG84 cartesian coordinate for which to to determine the geocentric normal.\n- `result` - Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter or a new `Vector3` instance if none was provided.\n\n#### geodeticSurfaceNormalCartographic(cartographic : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the normal of the plane tangent to the surface of the ellipsoid at the provided position.\n\n- `cartographic` The cartographic position for which to to determine the geodetic normal.\n- `result` Optional object onto which to store the result.\n\nReturns\n\nThe modified result parameter or a new `Vector3` instance if none was provided.\n\n#### geodeticSurfaceNormal(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the normal of the plane tangent to the surface of the ellipsoid at the provided position.\n\n- `cartesian` The Cartesian position for which to to determine the surface normal.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n#### cartographicToCartesian(cartographic : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nConverts the provided cartographic to Cartesian representation.\n\n- `cartographic` The cartographic position.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n#### cartesianToCartographic(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3] | `undefined`\n\nConverts the provided cartesian to cartographic representation. The cartesian is `undefined` at the center of the ellipsoid.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter, new `Vector3` instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\n#### scaleToGeodeticSurface(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3] | `undefined`\n\nScales the provided Cartesian position along the geodetic surface normal so that it is on the surface of this ellipsoid. If the position is at the center of the ellipsoid, this function returns `undefined`.\n\n- `cartesian` The Cartesian position to scale.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter, a new `Vector3` instance if none was provided, or undefined if the position is at the center.\n\n#### scaleToGeocentricSurface(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nScales the provided Cartesian position along the geocentric surface normal so that it is on the surface of this ellipsoid.\n\n- `cartesian` The Cartesian position to scale.\n- `result` Optional object onto which to store the result.\n\nReturns\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n#### transformPositionToScaledSpace(position : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nTransforms a Cartesian X, Y, Z position to the ellipsoid-scaled space by multiplying its components by the result of `Ellipsoid.oneOverRadii`.\n\n- `position` The position to transform.\n- `result` Optional array into which to copy the result.\n\nReturns\n\n- The position expressed in the scaled space. The returned instance is the one passed as the `result` parameter if it is not undefined, or a new instance of it is.\n\n#### transformPositionFromScaledSpace(position : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nTransforms a Cartesian X, Y, Z position from the ellipsoid-scaled space by multiplying its components by the result of `Ellipsoid.radii`.\n\n- `position` The position to transform.\n- `result` Optional array to which to copy the result.\n\nReturns\n\n- The position expressed in the unscaled space. The returned array is the one passed as the `result` parameter, or a new `Vector3` instance.\n\n#### getSurfaceNormalIntersectionWithZAxis(position, buffer, result) : | undefined\n\nComputes a point which is the intersection of the surface normal with the z-axis.\n\n- `position` the position. must be on the surface of the ellipsoid.\n- `buffer`=`0.0` A buffer to subtract from the ellipsoid size when checking if the point is inside the ellipsoid.\n- `result` Optional array into which to copy the result.\n\nReturns\n\n- The intersection point if it's inside the ellipsoid, `undefined` otherwise.\n\nThrows\n\n- `position` is required.\n- `Ellipsoid` must be an ellipsoid of revolution (`radii.x == radii.y`).\n- Ellipsoid.radii.z must be greater than 0.\n\nNotes:\n\n- In earth case, with common earth datums, there is no need for this buffer since the intersection point is always (relatively) very close to the center.\n- In WGS84 datum, intersection point is at max z = +-42841.31151331382 (0.673% of z-axis).\n- Intersection point could be outside the ellipsoid if the ratio of MajorAxis / AxisOfRotation is bigger than the square root of 2\n\n## Attribution\n\nThis class was ported from [Cesium](https://github.com/AnalyticalGraphicsInc/cesium) under the Apache 2 License.\n","slug":"docs/api-reference/math/geospatial/ellipsoid","title":"Ellipsoid"},{"excerpt":"@math.gl/geometry This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes…","rawMarkdownBody":"# @math.gl/geometry\n\n> This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes.\n\nClasses and utilities to help working with geometries (arrays of vertices) stored in typed arrays according to WebGL/OpenGL layout rules.\n\n## Usage Examples\n\n## Framework Independence\n\nLike all non-core math.gl modules, this library can be used without the math.gl core classes.\n\n- Any input vectors can be supplied as length 3 JavaScript `Array` instances.\n- Any result vectors can be treated as length 3 JavaScript `Array` instances (they may be math.gl `Vector3`).\n- The core math.gl classes inherit from JavaScript `Array` and can be used directly as input.\n","slug":"docs/api-reference/math/geometry","title":"@math.gl/geometry"},{"excerpt":"GLType Helper functions to work with WebGL data type constants. WebGL type constant JavaScript Typed Array Notes      Not yet directly…","rawMarkdownBody":"# GLType\n\nHelper functions to work with WebGL data type constants.\n\n| WebGL type constant | JavaScript Typed Array | Notes                                 |\n| ------------------- | ---------------------- | ------------------------------------- |\n| `GL.FLOAT`          | `Float32Array`         |                                       |\n| `GL.DOUBLE`         | `Float64Array`         | Not yet directly usable in WebGL/GLSL |\n| `GL.UNSIGNED_SHORT` | `Uint16Array`          |                                       |\n| `GL.UNSIGNED_INT`   | `Uint32Array`          |                                       |\n| `GL.UNSIGNED_BYTE`  | `Uint8Array`           |                                       |\n| `GL.UNSIGNED_BYTE`  | `Uint8ClampedArray`    |                                       |\n| `GL.BYTE`           | `Int8Array`            |                                       |\n| `GL.SHORT`          | `Int16Array`           |                                       |\n| `GL.INT`            | `Int32Array`           |                                       |\n\n## Usage\n\n```js\nimport {GL, GLType} from '@math.gl/geometry';\n// Returns Int8Array.BYTES_PER_ELEMENT\nvar size = GLType.getSizeInBytes(GL.BYTE);\n```\n\n## Static Methods\n\n### GLType.fromTypedArray(typedArray: Typed Array | Function) : Number\n\nReturns the size, in bytes, of the corresponding datatype.\n\n- `glType` The component datatype to get the size of.\n\nReturns\n\nThe size in bytes.\n\nThrows\n- glType is not a valid value.\n\n\nGets the {@link ComponentDatatype} for the provided TypedArray instance.\n\n-  array The typed array.\n\nReturns\n\nThe ComponentDatatype for the provided array, or undefined if the array is not a TypedArray.\n\n### GLType.getArrayType(glType: Number) : Function\n\nreturns the constructor of the array\n\n### static GLType.getByteSize(glType: Number) : Number\n\nReturns the size in bytes of one element of the provided WebGL type.\n\nEquivalent to `GLType.getArrayType(glType).BYTES_PER_ELEMENT`.\n\n### static GLType.validate(glType) : Boolean\n\nReturns `true` if `glType` is a valid WebGL data type.\n\n### static GLType.createTypedArray(glType : Number, buffer : ArrayBuffer [, byteOffset : Number [, length : Number]]) : TypedArray\n\nCreates a typed view of an array of bytes.\n\n- `glType` The type of typed array (ArrayBuffer view) to create.\n- `buffer` The buffer storage to use for the view.\n- `byteOffset`=`0` The offset, in bytes, to the first element in the view.\n- `length`= The number of elements in the view. Defaults to buffer length.\n\nReturns\n\n`Int8Array`|`Uint8Array`|`Int16Array`|`Uint16Array`|`Int32Array`|`Uint32Array`|`Float32Array`|`Float64Array` A typed array view of the buffer.\n\nThrows\n- `glType` is not a valid value.\n","slug":"docs/api-reference/math/geometry/gl-type","title":"GLType"}]}}}